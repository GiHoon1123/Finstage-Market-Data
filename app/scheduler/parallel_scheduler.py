"""
ë³‘ë ¬ ì²˜ë¦¬ ê¸°ëŠ¥ì´ ì¶”ê°€ëœ ìŠ¤ì¼€ì¤„ëŸ¬ ëŸ¬ë„ˆ
"""

from apscheduler.schedulers.background import BackgroundScheduler
from app.common.utils.parallel_executor import ParallelExecutor, measure_execution_time
from app.common.utils.logging_config import get_logger
from app.common.exceptions.handlers import handle_scheduler_errors, safe_execute
from app.common.exceptions.base import SchedulerError, ErrorCode

logger = get_logger("parallel_scheduler")
from app.common.constants.symbol_names import (
    INDEX_SYMBOLS,
    FUTURES_SYMBOLS,
    STOCK_SYMBOLS,
    SYMBOL_PRICE_MAP,
)
from app.common.constants.rss_feeds import (
    INVESTING_ECONOMIC_SYMBOLS,
    INVESTING_MARKET_SYMBOLS,
)


# ë³‘ë ¬ ì‹¤í–‰ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (max_workers ê°ì†Œë¡œ DB ì—°ê²° ë¶€í•˜ ê°ì†Œ)
executor = ParallelExecutor(max_workers=2)  # 3 â†’ 2ë¡œ ë” ê°ì†Œ


@measure_execution_time
@handle_scheduler_errors(reraise=False, return_on_error=None)
def run_integrated_news_crawling_parallel():
    """í†µí•© ë‰´ìŠ¤ í¬ë¡¤ë§ (ê²½ì œ ë‰´ìŠ¤ + ì§€ìˆ˜ ë‰´ìŠ¤)"""
    from app.news_crawler.service.investing_news_crawler import InvestingNewsCrawler
    from app.news_crawler.service.yahoo_news_crawler import YahooNewsCrawler

    logger.info(
        "integrated_news_crawling_started",
        sources=["investing_economic", "yahoo_index"],
    )

    # 1. Investing ê²½ì œ ë‰´ìŠ¤ í¬ë¡¤ë§
    def process_investing_symbol(symbol):
        logger.debug("processing_symbol", source="investing_economic", symbol=symbol)
        crawler = InvestingNewsCrawler(symbol)
        result = crawler.process_all()
        return result

    investing_results = executor.run_symbol_tasks_parallel(
        process_investing_symbol, INVESTING_ECONOMIC_SYMBOLS, delay=0.5
    )

    investing_success = sum(1 for r in investing_results if r is not None)
    logger.info(
        "news_crawling_completed",
        source="investing_economic",
        success_count=investing_success,
        total_count=len(INVESTING_ECONOMIC_SYMBOLS),
        success_rate=investing_success / len(INVESTING_ECONOMIC_SYMBOLS),
    )

    # 2. Yahoo ì§€ìˆ˜ ë‰´ìŠ¤ í¬ë¡¤ë§
    def process_yahoo_symbol(symbol):
        logger.debug("processing_symbol", source="yahoo_index", symbol=symbol)
        crawler = YahooNewsCrawler(symbol)
        result = crawler.process_all()
        return result

    yahoo_results = executor.run_symbol_tasks_parallel(
        process_yahoo_symbol, INDEX_SYMBOLS, delay=0.5
    )

    yahoo_success = sum(1 for r in yahoo_results if r is not None)
    logger.info(
        "news_crawling_completed",
        source="yahoo_index",
        success_count=yahoo_success,
        total_count=len(INDEX_SYMBOLS),
        success_rate=yahoo_success / len(INDEX_SYMBOLS),
    )

    total_success = investing_success + yahoo_success
    total_symbols = len(INVESTING_ECONOMIC_SYMBOLS) + len(INDEX_SYMBOLS)
    logger.info(
        "integrated_news_crawling_completed",
        total_success=total_success,
        total_symbols=total_symbols,
        overall_success_rate=total_success / total_symbols,
    )


@measure_execution_time
@handle_scheduler_errors(reraise=False, return_on_error=None)
def run_investing_market_news_parallel():
    """Investing ì‹œì¥ ë‰´ìŠ¤ í¬ë¡¤ë§ (ë³‘ë ¬)"""
    from app.news_crawler.service.investing_news_crawler import InvestingNewsCrawler

    logger.info("news_crawling_started", source="investing_market")

    def process_symbol(symbol):
        logger.debug("processing_symbol", source="investing_market", symbol=symbol)
        crawler = InvestingNewsCrawler(symbol)
        result = crawler.process_all()
        return result

    # ë³‘ë ¬ ì‹¤í–‰ (API ì œí•œ ê³ ë ¤í•˜ì—¬ ì•½ê°„ì˜ ì§€ì—° ì¶”ê°€)
    results = executor.run_symbol_tasks_parallel(
        process_symbol, INVESTING_MARKET_SYMBOLS, delay=0.5
    )

    success_count = sum(1 for r in results if r is not None)
    logger.info(
        "news_crawling_completed",
        source="investing_market",
        success_count=success_count,
        total_count=len(INVESTING_MARKET_SYMBOLS),
        success_rate=success_count / len(INVESTING_MARKET_SYMBOLS),
    )


@measure_execution_time
@handle_scheduler_errors(reraise=False, return_on_error=None)
def run_yahoo_futures_news_parallel():
    """Yahoo ì„ ë¬¼ ë‰´ìŠ¤ í¬ë¡¤ë§ (ë³‘ë ¬)"""
    from app.news_crawler.service.yahoo_news_crawler import YahooNewsCrawler

    logger.info("news_crawling_started", source="yahoo_futures")

    def process_symbol(symbol):
        logger.debug("processing_symbol", source="yahoo_futures", symbol=symbol)
        crawler = YahooNewsCrawler(symbol)
        result = crawler.process_all()
        return result

    # ë³‘ë ¬ ì‹¤í–‰ (API ì œí•œ ê³ ë ¤í•˜ì—¬ ì•½ê°„ì˜ ì§€ì—° ì¶”ê°€)
    results = executor.run_symbol_tasks_parallel(
        process_symbol, FUTURES_SYMBOLS, delay=0.5
    )

    success_count = sum(1 for r in results if r is not None)
    logger.info(
        "news_crawling_completed",
        source="yahoo_futures",
        success_count=success_count,
        total_count=len(FUTURES_SYMBOLS),
        success_rate=success_count / len(FUTURES_SYMBOLS),
    )


# ê¸°ì¡´ ê°œë³„ ë‰´ìŠ¤ í¬ë¡¤ë§ í•¨ìˆ˜ë“¤ì€ í†µí•© í•¨ìˆ˜ë¡œ ëŒ€ì²´ë¨
# run_investing_economic_news_parallel() -> run_integrated_news_crawling_parallel()
# run_yahoo_index_news_parallel() -> run_integrated_news_crawling_parallel()


@measure_execution_time
@handle_scheduler_errors(reraise=False, return_on_error=None)
def run_yahoo_stock_news_parallel():
    """Yahoo ì¢…ëª© ë‰´ìŠ¤ í¬ë¡¤ë§ (ë³‘ë ¬)"""
    from app.news_crawler.service.yahoo_news_crawler import YahooNewsCrawler

    logger.info("news_crawling_started", source="yahoo_stocks")

    def process_symbol(symbol):
        logger.debug("processing_symbol", source="yahoo_stocks", symbol=symbol)
        crawler = YahooNewsCrawler(symbol)
        result = crawler.process_all()
        return result

    # ë³‘ë ¬ ì‹¤í–‰ (API ì œí•œ ê³ ë ¤í•˜ì—¬ ì•½ê°„ì˜ ì§€ì—° ì¶”ê°€)
    results = executor.run_symbol_tasks_parallel(
        process_symbol, STOCK_SYMBOLS, delay=0.5
    )

    success_count = sum(1 for r in results if r is not None)
    logger.info(
        "news_crawling_completed",
        source="yahoo_stocks",
        success_count=success_count,
        total_count=len(STOCK_SYMBOLS),
        success_rate=success_count / len(STOCK_SYMBOLS),
    )


@measure_execution_time
@handle_scheduler_errors(reraise=False, return_on_error=None)
def run_high_price_update_job_parallel():
    """ìƒì¥ í›„ ìµœê³ ê°€ ê°±ì‹  (ë³‘ë ¬)"""
    from app.market_price.service.price_high_record_service import (
        PriceHighRecordService,
    )

    logger.info("high_price_update_started")

    def update_high_price(symbol):
        return safe_execute(
            lambda: _update_high_price_for_symbol(symbol),
            default_return=None,
            log_errors=True,
        )

    def _update_high_price_for_symbol(symbol):
        service = PriceHighRecordService()
        result = service.update_all_time_high(symbol)
        # ì„œë¹„ìŠ¤ ì‚¬ìš© í›„ ì„¸ì…˜ ì •ë¦¬
        if hasattr(service, "__del__"):
            service.__del__()
        return result

    # ë³‘ë ¬ ì‹¤í–‰ (API ì œí•œ ê³ ë ¤í•˜ì—¬ ì•½ê°„ì˜ ì§€ì—° ì¶”ê°€)
    results = executor.run_symbol_tasks_parallel(
        update_high_price,
        list(SYMBOL_PRICE_MAP.keys()),
        delay=2.0,  # 0.5 â†’ 2.0ìœ¼ë¡œ ì¦ê°€
    )

    success_count = sum(1 for r in results if r is not None)
    logger.info(
        "high_price_update_completed",
        success_count=success_count,
        total_count=len(SYMBOL_PRICE_MAP),
        success_rate=success_count / len(SYMBOL_PRICE_MAP),
    )


@measure_execution_time
@handle_scheduler_errors(reraise=False, return_on_error=None)
def run_previous_close_snapshot_job_parallel():
    """ì „ì¼ ì¢…ê°€ ì €ì¥ (ë³‘ë ¬)"""
    from app.market_price.service.price_snapshot_service import PriceSnapshotService

    logger.info("previous_close_snapshot_started")

    def save_previous_close(symbol):
        service = PriceSnapshotService()
        result = service.save_previous_close_if_needed(symbol)
        return result

    # ë³‘ë ¬ ì‹¤í–‰ (API ì œí•œ ê³ ë ¤í•˜ì—¬ ì•½ê°„ì˜ ì§€ì—° ì¶”ê°€)
    results = executor.run_symbol_tasks_parallel(
        save_previous_close, list(SYMBOL_PRICE_MAP.keys()), delay=0.5
    )

    success_count = sum(1 for r in results if r is not None)
    logger.info(
        "previous_close_snapshot_completed",
        success_count=success_count,
        total_count=len(SYMBOL_PRICE_MAP),
        success_rate=success_count / len(SYMBOL_PRICE_MAP),
    )


@measure_execution_time
@handle_scheduler_errors(reraise=False, return_on_error=None)
def run_previous_high_snapshot_job_parallel():
    """ì „ì¼ ê³ ì  ì €ì¥ (ë³‘ë ¬)"""
    from app.market_price.service.price_snapshot_service import PriceSnapshotService

    logger.info("previous_high_snapshot_started")

    def save_previous_high(symbol):
        service = PriceSnapshotService()
        result = service.save_previous_high_if_needed(symbol)
        return result

    # ë³‘ë ¬ ì‹¤í–‰ (API ì œí•œ ê³ ë ¤í•˜ì—¬ ì•½ê°„ì˜ ì§€ì—° ì¶”ê°€)
    results = executor.run_symbol_tasks_parallel(
        save_previous_high, list(SYMBOL_PRICE_MAP.keys()), delay=0.5
    )

    success_count = sum(1 for r in results if r is not None)
    logger.info(
        "previous_high_snapshot_completed",
        success_count=success_count,
        total_count=len(SYMBOL_PRICE_MAP),
        success_rate=success_count / len(SYMBOL_PRICE_MAP),
    )


@measure_execution_time
@handle_scheduler_errors(reraise=False, return_on_error=None)
def run_previous_low_snapshot_job_parallel():
    """ì „ì¼ ì €ì  ì €ì¥ (ë³‘ë ¬)"""
    from app.market_price.service.price_snapshot_service import PriceSnapshotService

    logger.info("previous_low_snapshot_started")

    def save_previous_low(symbol):
        service = PriceSnapshotService()
        result = service.save_previous_low_if_needed(symbol)
        return result

    # ë³‘ë ¬ ì‹¤í–‰ (API ì œí•œ ê³ ë ¤í•˜ì—¬ ì•½ê°„ì˜ ì§€ì—° ì¶”ê°€)
    results = executor.run_symbol_tasks_parallel(
        save_previous_low, list(SYMBOL_PRICE_MAP.keys()), delay=0.5
    )

    success_count = sum(1 for r in results if r is not None)
    logger.info(
        "previous_low_snapshot_completed",
        success_count=success_count,
        total_count=len(SYMBOL_PRICE_MAP),
        success_rate=success_count / len(SYMBOL_PRICE_MAP),
    )


@measure_execution_time
@handle_scheduler_errors(reraise=False, return_on_error=None)
def run_realtime_price_monitor_job_parallel():
    """ì‹¤ì‹œê°„ ê°€ê²© ëª¨ë‹ˆí„°ë§ (ë³‘ë ¬)"""
    from app.market_price.service.price_monitor_service import PriceMonitorService
    from app.common.utils.db_session_manager import session_scope

    logger.info("realtime_price_monitoring_started")

    def check_price(symbol):
        return safe_execute(
            lambda: _check_price_for_symbol(symbol),
            default_return=None,
            log_errors=True,
        )

    def _check_price_for_symbol(symbol):
        # ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì‚¬ìš©
        with session_scope() as session:
            service = PriceMonitorService()
            # ì„¸ì…˜ ëª…ì‹œì  ì „ë‹¬ (ê°€ëŠ¥í•œ ê²½ìš°)
            if hasattr(service, "set_session"):
                service.set_session(session)
            result = service.check_price_against_baseline(symbol)
            return result

    # ë³‘ë ¬ ì‹¤í–‰ (ë°°ì¹˜ í¬ê¸° ì œí•œ ë° ì§€ì—° ì‹œê°„ ì¦ê°€)
    results = executor.run_symbol_tasks_parallel(
        check_price, list(SYMBOL_PRICE_MAP.keys()), delay=1.0  # 0.5 â†’ 1.0ìœ¼ë¡œ ì¦ê°€
    )

    success_count = sum(1 for r in results if r is not None)
    logger.info(
        "realtime_price_monitoring_completed",
        success_count=success_count,
        total_count=len(SYMBOL_PRICE_MAP),
        success_rate=success_count / len(SYMBOL_PRICE_MAP),
    )


def start_parallel_scheduler():
    """ë³‘ë ¬ ì²˜ë¦¬ ê¸°ëŠ¥ì´ ì¶”ê°€ëœ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
    scheduler = BackgroundScheduler()

    logger.info("parallel_scheduler_starting")

    # ğŸ†• í†µí•© ë‰´ìŠ¤ í¬ë¡¤ë§ ì‘ì—… (ê²½ì œ ë‰´ìŠ¤ + ì§€ìˆ˜ ë‰´ìŠ¤)
    scheduler.add_job(
        run_integrated_news_crawling_parallel, "interval", minutes=90
    )  # í†µí•© ë‰´ìŠ¤ 90ë¶„ë§ˆë‹¤ (ê¸°ì¡´ 60ë¶„Ã—2 â†’ 90ë¶„Ã—1ë¡œ ìµœì í™”)

    # ğŸ†• ëª¨ë“  ì¢…ëª© ë‰´ìŠ¤ í¬ë¡¤ë§ í™œì„±í™” (ë°ì´í„° íë¦„ í™•ì¸ìš©)
    scheduler.add_job(
        run_yahoo_futures_news_parallel, "interval", hours=2
    )  # ì„ ë¬¼ ë‰´ìŠ¤ 2ì‹œê°„ë§ˆë‹¤
    scheduler.add_job(
        run_yahoo_stock_news_parallel, "interval", hours=3
    )  # ì¢…ëª© ë‰´ìŠ¤ 3ì‹œê°„ë§ˆë‹¤
    scheduler.add_job(
        run_investing_market_news_parallel, "interval", hours=4
    )  # ì‹œì¥ ë‰´ìŠ¤ 4ì‹œê°„ë§ˆë‹¤

    # ê°€ê²© ê´€ë ¨ ì‘ì—… (í•µì‹¬ë§Œ ìœ ì§€) - ì£¼ìš” ì§€ìˆ˜ë§Œ ëª¨ë‹ˆí„°ë§
    scheduler.add_job(
        run_high_price_update_job_parallel,
        "interval",
        hours=4,  # 2ì‹œê°„ â†’ 4ì‹œê°„ìœ¼ë¡œ ë” ê°ì†Œ
    )

    # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ (í•µì‹¬ë§Œ) - ê°„ê²© ë” ì¦ê°€
    scheduler.add_job(
        run_realtime_price_monitor_job_parallel, "interval", minutes=30
    )  # 10ë¶„ â†’ 30ë¶„ìœ¼ë¡œ ëŒ€í­ ê°ì†Œ

    # ìŠ¤ëƒ…ìƒ· ì‘ì—…ë“¤ ì œê±° (ì¼ì¼ ë¦¬í¬íŠ¸ì—ì„œ ì¶©ë¶„íˆ ì»¤ë²„)
    # scheduler.add_job(run_previous_close_snapshot_job_parallel, ...)  # ì œê±°
    # scheduler.add_job(run_previous_high_snapshot_job_parallel, ...)   # ì œê±°
    # scheduler.add_job(run_previous_low_snapshot_job_parallel, ...)    # ì œê±°

    # ê¸°ì¡´ ê¸°ìˆ ì  ì§€í‘œ ëª¨ë‹ˆí„°ë§ ì‘ì—…ë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
    from app.scheduler.scheduler_runner import (
        run_daily_index_analysis,
        run_outcome_tracking_update,
        initialize_recent_signals_tracking,
        run_pattern_discovery,
    )

    # ì¼ì¼ ì§€ìˆ˜ ë¶„ì„ì€ scheduler_runner.pyì—ì„œ ì˜¤ì „ 7ì‹œì—ë§Œ ì‹¤í–‰
    # scheduler.add_job(run_daily_index_analysis, "interval", hours=1)  # ì œê±°ë¨
    scheduler.add_job(run_outcome_tracking_update, "interval", hours=1)
    scheduler.add_job(initialize_recent_signals_tracking, "interval", hours=6)

    # ğŸ†• íŒ¨í„´ ë°œê²¬ ë° ë¶„ì„ (ë§¤ì¼ ì˜¤ì „ 6ì‹œ)
    scheduler.add_job(
        run_pattern_discovery, "cron", hour=6, minute=0, timezone="Asia/Seoul"
    )

    # ğŸ†• ì¼ì¼ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ (ë§¤ì¼ ì˜¤ì „ 8ì‹œ)
    scheduler.add_job(
        run_daily_comprehensive_report, "cron", hour=8, minute=0, timezone="Asia/Seoul"
    )

    logger.info("parallel_scheduler_started")
    scheduler.start()


@measure_execution_time
@handle_scheduler_errors(reraise=False, return_on_error=None)
def run_daily_comprehensive_report():
    """
    ì¼ì¼ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ë° ì „ì†¡
    - ë°±í…ŒìŠ¤íŒ… ì„±ê³¼ ë¶„ì„
    - íŒ¨í„´ ë¶„ì„ ê²°ê³¼
    - ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ë¶„ì„
    - íˆ¬ì ì¸ì‚¬ì´íŠ¸ ì œê³µ
    """
    logger.info("daily_comprehensive_report_started")

    from app.technical_analysis.service.daily_comprehensive_report_service import (
        DailyComprehensiveReportService,
    )

    service = DailyComprehensiveReportService()
    result = service.generate_daily_report()

    if result and "error" in result:
        raise SchedulerError(
            message=f"ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {result['error']}",
            error_code=ErrorCode.TASK_EXECUTION_ERROR,
            details={"service": "daily_comprehensive_report", "result": result},
        )
    else:
        logger.info("daily_comprehensive_report_completed")
