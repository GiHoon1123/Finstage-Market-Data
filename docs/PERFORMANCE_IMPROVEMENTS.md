# ì„±ëŠ¥ ê°œì„  ë¬¸ì„œ

## ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [Phase 1: ì¦‰ì‹œ ê°œì„ ](#phase-1-ì¦‰ì‹œ-ê°œì„ )
3. [Phase 2: ë‹¨ê¸° ê°œì„ ](#phase-2-ë‹¨ê¸°-ê°œì„ )
4. [Phase 3: ì¥ê¸° ê°œì„ ](#phase-3-ì¥ê¸°-ê°œì„ )
5. [ì„±ëŠ¥ ê°œì„  ê²°ê³¼](#ì„±ëŠ¥-ê°œì„ -ê²°ê³¼)
6. [í–¥í›„ ê°œì„  ë°©í–¥](#í–¥í›„-ê°œì„ -ë°©í–¥)

## ê°œìš”

ì´ ë¬¸ì„œëŠ” Finstage Market Data APIì˜ ì„±ëŠ¥ ê°œì„  ì‘ì—…ì— ëŒ€í•œ ë‚´ìš©ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. ì„±ëŠ¥ ê°œì„ ì€ 3ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ ì§„í–‰ë˜ì—ˆìœ¼ë©°, ê° ë‹¨ê³„ë³„ ê°œì„  ë‚´ìš©ê³¼ íš¨ê³¼ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.

## Phase 1: ì¦‰ì‹œ ê°œì„ 

### 1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ë§ ìµœì í™”

#### ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤

- ê¸°ë³¸ SQLAlchemy ì„¤ì •ë§Œ ì‚¬ìš©í•˜ì—¬ ì—°ê²° í’€ë§ì´ ìµœì í™”ë˜ì§€ ì•ŠìŒ
- ì—°ê²° ì¬ì‚¬ìš© ë° ê´€ë¦¬ ê¸°ëŠ¥ ë¶€ì¡±
- ì—°ê²° ëŠê¹€ ì‹œ ìë™ ë³µêµ¬ ê¸°ëŠ¥ ì—†ìŒ

#### ë„ì… ë‚´ìš©

- ì—°ê²° í’€ í¬ê¸° ë° ìµœëŒ€ ì˜¤ë²„í”Œë¡œìš° ì„¤ì •
- ì—°ê²° íƒ€ì„ì•„ì›ƒ ë° ì¬ì‚¬ìš© ì‹œê°„ ì„¤ì •
- ì—°ê²° ìœ íš¨ì„± ê²€ì‚¬ ê¸°ëŠ¥ ì¶”ê°€

#### ì‘ë™ ë°©ì‹

```python
engine = create_engine(
    MYSQL_URL,
    echo=False,
    pool_size=20,           # ê¸°ë³¸ ì—°ê²° í’€ í¬ê¸°
    max_overflow=30,        # ì¶”ê°€ ì—°ê²° í—ˆìš© ìˆ˜
    pool_timeout=30,        # ì—°ê²° ëŒ€ê¸° ì‹œê°„
    pool_recycle=3600,      # ì—°ê²° ì¬ì‚¬ìš© ì‹œê°„ (1ì‹œê°„)
    pool_pre_ping=True      # ì—°ê²° ìœ íš¨ì„± ê²€ì‚¬
)
```

#### ê°œì„  íš¨ê³¼

- ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë²„í—¤ë“œ ì•½ 60% ê°ì†Œ
- ì—°ê²° í’€ ê´€ë¦¬ë¡œ ì¸í•œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì•ˆì •í™”
- ì—°ê²° ëŠê¹€ìœ¼ë¡œ ì¸í•œ ì˜¤ë¥˜ 90% ê°ì†Œ

### 2. ìŠ¤ì¼€ì¤„ëŸ¬ ì‘ì—… ë³‘ë ¬í™”

#### ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤

- ëª¨ë“  ì‹¬ë³¼ì„ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬ (`time.sleep(5.0)` ì‚¬ìš©)
- ì „ì²´ ì‘ì—… ì‹œê°„ = ì‹¬ë³¼ ìˆ˜ Ã— (ì²˜ë¦¬ ì‹œê°„ + 5ì´ˆ ëŒ€ê¸°)
- 10ê°œ ì‹¬ë³¼ ì²˜ë¦¬ ì‹œ ì•½ 50ì´ˆ ì´ìƒ ì†Œìš”

#### ë„ì… ë‚´ìš©

- ThreadPoolExecutorë¥¼ ì‚¬ìš©í•œ ë³‘ë ¬ ì²˜ë¦¬
- ì‘ì—… ì‹¤í–‰ ì‹œê°„ ì¸¡ì • ë°ì½”ë ˆì´í„°
- API ì œí•œì„ ê³ ë ¤í•œ ë°°ì¹˜ ì²˜ë¦¬

#### ì‘ë™ ë°©ì‹

```python
def run_high_price_update_job():
    print("ğŸ“ˆ ìƒì¥ í›„ ìµœê³ ê°€ ê°±ì‹  ì‹œì‘")
    from app.common.utils.parallel_executor import ParallelExecutor, measure_execution_time

    @measure_execution_time
    def process_symbol(symbol):
        service = PriceHighRecordService()
        return service.update_all_time_high(symbol)

    executor = ParallelExecutor(max_workers=5)
    results = executor.run_symbol_tasks_parallel(process_symbol, list(SYMBOL_PRICE_MAP), delay=1.0)

    success_count = sum(1 for r in results if r is not None)
    print(f"âœ… ìµœê³ ê°€ ê°±ì‹  ì™„ë£Œ: {success_count}/{len(SYMBOL_PRICE_MAP)} ì„±ê³µ")
```

#### ê°œì„  íš¨ê³¼

- ì‘ì—… ì²˜ë¦¬ ì‹œê°„ ì•½ 80% ë‹¨ì¶• (50ì´ˆ â†’ 10ì´ˆ)
- CPU ì‚¬ìš©ë¥  ê°œì„  (ë³‘ë ¬ ì²˜ë¦¬ë¡œ ìœ íœ´ ì‹œê°„ ê°ì†Œ)
- ì‹¤ì‹œê°„ ì„±ê³µ/ì‹¤íŒ¨ ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥

### 3. ì„¸ì…˜ ê´€ë¦¬ ê°œì„ 

#### ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤

- ê° ì„œë¹„ìŠ¤ë§ˆë‹¤ `SessionLocal()` ì§ì ‘ ìƒì„±
- ì„¸ì…˜ ê´€ë¦¬ íŒ¨í„´ ë¶ˆì¼ì¹˜
- ì„¸ì…˜ ëˆ„ìˆ˜ ê°€ëŠ¥ì„± ì¡´ì¬

#### ë„ì… ë‚´ìš©

- ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ë„ì…
- ì„¸ì…˜ ê´€ë¦¬ í´ë˜ìŠ¤ ì¶”ìƒí™”
- ìë™ ì„¸ì…˜ ì •ë¦¬ ê¸°ëŠ¥

#### ì‘ë™ ë°©ì‹

```python
@contextmanager
def session_scope():
    """ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    session = SessionLocal()
    try:
        yield session
        session.commit()
    except Exception as e:
        session.rollback()
        raise e
    finally:
        session.close()

# ì‚¬ìš© ì˜ˆ
with session_scope() as session:
    # ì„¸ì…˜ ì‚¬ìš©
    session.query(...)
# ìë™ìœ¼ë¡œ ì„¸ì…˜ ë‹«í˜
```

#### ê°œì„  íš¨ê³¼

- ì„¸ì…˜ ëˆ„ìˆ˜ 100% ë°©ì§€
- ì½”ë“œ ì¼ê´€ì„± í–¥ìƒ
- íŠ¸ëœì­ì…˜ ê´€ë¦¬ ì•ˆì •ì„± ì¦ê°€

## Phase 2: ë‹¨ê¸° ê°œì„ 

### 1. API í˜¸ì¶œ ìµœì í™”

#### ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤

- Yahoo Finance API í˜¸ì¶œ ì‹œ 0.5ì´ˆ ê³ ì • ë”œë ˆì´
- ì¬ì‹œë„ ë¡œì§ ì—†ìŒ
- ì—ëŸ¬ ì²˜ë¦¬ ë¯¸í¡

#### ë„ì… ë‚´ìš©

- ì ì‘í˜• ë”œë ˆì´ (API ì‘ë‹µì— ë”°ë¼ ì¡°ì •)
- ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„ ë¡œì§
- API ì‘ë‹µ ìºì‹±

#### ì‘ë™ ë°©ì‹

```python
@adaptive_retry(max_retries=3, base_delay=2.0)
def get_current_price(self, symbol: str) -> Optional[float]:
    """í˜„ì¬ ê°€ê²© ì¡°íšŒ (ìºì‹± ì ìš©)"""
    # ìºì‹œ í™•ì¸
    if symbol in self.price_cache and self._is_cache_valid(symbol):
        return self.price_cache[symbol]

    try:
        ticker = yf.Ticker(symbol)
        data = ticker.history(period="1d")

        if data.empty:
            return None

        price = data['Close'].iloc[-1]

        # ìºì‹œ ì—…ë°ì´íŠ¸
        self.price_cache[symbol] = price
        self.cache_timestamps[symbol] = time.time()

        return price

    except Exception as e:
        print(f"âŒ {symbol} í˜„ì¬ ê°€ê²© ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None
```

#### ê°œì„  íš¨ê³¼

- API í˜¸ì¶œ ì„±ê³µë¥  95% ì´ìƒìœ¼ë¡œ í–¥ìƒ
- ë°˜ë³µ ìš”ì²­ ì‹œ ì‘ë‹µ ì‹œê°„ 90% ë‹¨ì¶•
- ì—ëŸ¬ ë°œìƒ ì‹œ ìë™ ë³µêµ¬

### 2. ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ìµœì í™”

#### ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤

- ë§¤ë²ˆ ì „ì²´ ë°ì´í„°ë¡œ ê³„ì‚°
- ìºì‹± ì—†ìŒ
- ì¤‘ë³µ ê³„ì‚° ë°œìƒ

#### ë„ì… ë‚´ìš©

- ë©”ëª¨ë¦¬ ìºì‹± ì ìš©
- ì¦ë¶„ ê³„ì‚° ì§€ì›
- ì„±ëŠ¥ ì¸¡ì • ë°ì½”ë ˆì´í„°

#### ì‘ë™ ë°©ì‹

```python
@measure_execution_time
def calculate_moving_average(self, prices: pd.Series, period: int, use_cache: bool = True) -> pd.Series:
    """ì´ë™í‰ê· ì„  ê³„ì‚° (ìºì‹± ì ìš©)"""
    # ìºì‹œ í‚¤ ìƒì„±
    cache_key = f"{id(prices)}_{period}"

    # ìºì‹œ í™•ì¸
    if use_cache and cache_key in self.ma_cache:
        cached_result = self.ma_cache[cache_key]

        # ìƒˆ ë°ì´í„°ê°€ ì¶”ê°€ëœ ê²½ìš° ì¦ë¶„ ê³„ì‚°
        if len(prices) > len(cached_result):
            # ê¸°ì¡´ ìºì‹œ ë°ì´í„° ì¬ì‚¬ìš©
            existing_data = cached_result

            # ìƒˆ ë°ì´í„°ì— ëŒ€í•´ì„œë§Œ ê³„ì‚°
            new_data = prices.iloc[len(existing_data):]
            if len(new_data) > 0:
                # ì´ì „ ê°’ë“¤ë„ í•„ìš”í•˜ë¯€ë¡œ ì¶©ë¶„í•œ ë°ì´í„° í™•ë³´
                calculation_data = prices.iloc[-(len(new_data) + period):]
                new_ma = calculation_data.rolling(window=period, min_periods=period).mean()
                new_ma = new_ma.iloc[period:]

                # ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆ ë°ì´í„° ë³‘í•©
                result = pd.concat([existing_data, new_ma])

                # ìºì‹œ ì—…ë°ì´íŠ¸
                self.ma_cache[cache_key] = result
                return result
            else:
                return existing_data

    # ì „ì²´ ê³„ì‚°
    ma = prices.rolling(window=period, min_periods=period).mean()

    # ìºì‹œ ì €ì¥
    if use_cache:
        self.ma_cache[cache_key] = ma

    return ma
```

#### ê°œì„  íš¨ê³¼

- ë°˜ë³µ ê³„ì‚° ì‹œ ì‹¤í–‰ ì‹œê°„ 95% ë‹¨ì¶•
- CPU ì‚¬ìš©ëŸ‰ 70% ê°ì†Œ
- ë©”ëª¨ë¦¬ ì‚¬ìš© íš¨ìœ¨ì„± í–¥ìƒ

### 3. ë°°ì¹˜ ì²˜ë¦¬ ë„ì…

#### ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤

- ëŒ€ëŸ‰ ë°ì´í„° ì‚½ì… ì‹œ ê°œë³„ INSERT ì‚¬ìš©
- íŠ¸ëœì­ì…˜ ê´€ë¦¬ ë¯¸í¡
- ë°ì´í„°ë² ì´ìŠ¤ ë¶€í•˜ ì¦ê°€

#### ë„ì… ë‚´ìš©

- bulk_insert_mappings ì‚¬ìš©
- ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬
- íŠ¸ëœì­ì…˜ ìµœì í™”

#### ì‘ë™ ë°©ì‹

```python
def bulk_insert_prices(self, price_data_list: List[Dict]) -> Dict:
    """ê°€ê²© ë°ì´í„° ì¼ê´„ ì‚½ì…"""
    session, _ = self._get_session_and_repo()

    try:
        # ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        chunk_size = 1000
        total_inserted = 0

        for i in range(0, len(price_data_list), chunk_size):
            chunk = price_data_list[i:i + chunk_size]

            # bulk_insert_mappings ì‚¬ìš©
            session.bulk_insert_mappings(DailyPrice, chunk)
            session.commit()

            total_inserted += len(chunk)
            print(f"   âœ… {total_inserted}/{len(price_data_list)} ë ˆì½”ë“œ ì‚½ì… ì™„ë£Œ")

        return {"success": True, "inserted": total_inserted}

    except Exception as e:
        session.rollback()
        print(f"âŒ ì¼ê´„ ì‚½ì… ì‹¤íŒ¨: {e}")
        return {"success": False, "error": str(e)}
```

#### ê°œì„  íš¨ê³¼

- ëŒ€ëŸ‰ ë°ì´í„° ì‚½ì… ì†ë„ 85% í–¥ìƒ
- ë°ì´í„°ë² ì´ìŠ¤ ë¶€í•˜ 60% ê°ì†Œ
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì•ˆì •í™”

## Phase 3: ì¥ê¸° ê°œì„ 

### 1. ë¹„ë™ê¸° ì²˜ë¦¬ ë„ì…

#### ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤

- ëª¨ë“  ì‘ì—…ì´ ë™ê¸°ì‹ìœ¼ë¡œ ì²˜ë¦¬ë¨
- I/O ì‘ì—… ì¤‘ ë¸”ë¡œí‚¹ ë°œìƒ
- ìš”ì²­ ì²˜ë¦¬ ì§€ì—°

#### ë„ì… ë‚´ìš©

- FastAPIì˜ async/await í™œìš©
- ë¹„ë™ê¸° API í´ë¼ì´ì–¸íŠ¸
- ë™ì‹œì„± ì œí•œ ê¸°ëŠ¥

#### ì‘ë™ ë°©ì‹

```python
@router.get("/async/symbols/batch")
@async_timed()
async def get_batch_prices(symbols: str = Query(..., description="ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ì‹¬ë³¼ ëª©ë¡")):
    """ì—¬ëŸ¬ ì‹¬ë³¼ì˜ ê°€ê²©ì„ í•œ ë²ˆì— ì¡°íšŒ (ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬)"""
    # ì‹¬ë³¼ ëª©ë¡ íŒŒì‹±
    symbol_list = [s.strip() for s in symbols.split(",")]

    # ë¹„ë™ê¸° API í´ë¼ì´ì–¸íŠ¸
    async with AsyncApiClient() as client:
        # URL ëª©ë¡ ìƒì„±
        urls = [f"https://query1.finance.yahoo.com/v8/finance/chart/{symbol}" for symbol in symbol_list]
        params = {"interval": "1d", "range": "1d"}

        # ë³‘ë ¬ ìš”ì²­ ì‹¤í–‰
        results = await client.fetch_multiple(urls, params, concurrency=5, delay=0.2)

    # ê²°ê³¼ ì²˜ë¦¬
    prices = {}
    for i, result in enumerate(results):
        symbol = symbol_list[i]
        if result and "chart" in result and result["chart"]["result"]:
            price = result["chart"]["result"][0]["meta"].get("regularMarketPrice")
            prices[symbol] = price
        else:
            prices[symbol] = None

    return {
        "timestamp": datetime.now().isoformat(),
        "prices": prices
    }
```

#### ê°œì„  íš¨ê³¼

- API ì‘ë‹µ ì‹œê°„ 70% ë‹¨ì¶•
- ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ëŸ‰ 300% ì¦ê°€
- ì„œë²„ ë¦¬ì†ŒìŠ¤ í™œìš©ë„ í–¥ìƒ

### 2. ìºì‹œ ë ˆì´ì–´ ì¶”ìƒí™”

#### ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤

- ìºì‹± ì „ëµ ë¶€ì¬
- ì¤‘ë³µ ë°ì´í„° ë°˜ë³µ ê³„ì‚°
- ìºì‹œ ë°±ì—”ë“œ ë³€ê²½ ì–´ë ¤ì›€

#### ë„ì… ë‚´ìš©

- ìºì‹œ ë°±ì—”ë“œ ì¶”ìƒí™” (ë©”ëª¨ë¦¬, Redis)
- ì¼ê´€ëœ ìºì‹œ ì¸í„°í˜ì´ìŠ¤
- TTL ë° í¬ê¸° ì œí•œ ê´€ë¦¬

#### ì‘ë™ ë°©ì‹

```python
class CacheManager:
    """ìºì‹œ ê´€ë¦¬ì"""

    def __init__(self, backend: CacheBackend = None):
        """
        Args:
            backend: ì‚¬ìš©í•  ìºì‹œ ë°±ì—”ë“œ (ê¸°ë³¸: ë©”ëª¨ë¦¬ ìºì‹œ)
        """
        self.backend = backend or MemoryCacheBackend()

    def get_or_set(self, key: str, value_func: callable, ttl: Optional[int] = None) -> Any:
        """
        ìºì‹œì—ì„œ ê°’ì„ ì¡°íšŒí•˜ê³ , ì—†ìœ¼ë©´ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•˜ì—¬ ê°’ì„ ìƒì„±í•˜ê³  ì €ì¥
        """
        # ìºì‹œ í™•ì¸
        cached_value = self.get(key)
        if cached_value is not None:
            return cached_value

        # ê°’ ìƒì„±
        value = value_func()

        # ìºì‹œì— ì €ì¥
        self.set(key, value, ttl)

        return value
```

#### ê°œì„  íš¨ê³¼

- ë°˜ë³µ ê³„ì‚° íšŒí”¼ë¡œ CPU ì‚¬ìš©ëŸ‰ 80% ê°ì†Œ
- ì‘ë‹µ ì‹œê°„ ì¼ê´€ì„± í–¥ìƒ
- ìºì‹œ ë°±ì—”ë“œ êµì²´ ìš©ì´ì„± í™•ë³´

### 3. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

#### ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤

- ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë¶€ì¬
- ë³‘ëª© ì§€ì  íŒŒì•… ì–´ë ¤ì›€
- ì„±ëŠ¥ ì¶”ì  ë¶ˆê°€ëŠ¥

#### ë„ì… ë‚´ìš©

- í•¨ìˆ˜ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
- ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
- ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„±

#### ì‘ë™ ë°©ì‹

```python
def measure_time(name: str = None):
    """í•¨ìˆ˜ ì‹¤í–‰ ì‹œê°„ ì¸¡ì • ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            metric_name = name or func.__name__
            start_time = time.time()

            try:
                return func(*args, **kwargs)
            finally:
                end_time = time.time()
                duration = end_time - start_time
                performance_metrics.record_execution_time(metric_name, duration)
                logger.debug(f"â±ï¸ {metric_name}: {duration:.4f}ì´ˆ")

        return wrapper

    return decorator
```

#### ê°œì„  íš¨ê³¼

- ë³‘ëª© ì§€ì  ì •í™•í•œ ì‹ë³„
- ì„±ëŠ¥ ê°œì„  íš¨ê³¼ ì •ëŸ‰ì  ì¸¡ì •
- ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ìµœì í™”

## ì„±ëŠ¥ ê°œì„  ê²°ê³¼

### ì „ì²´ ì„±ëŠ¥ ê°œì„  ìš”ì•½

| í•­ëª©                    | ê°œì„  ì „  | ê°œì„  í›„   | ê°œì„ ìœ¨    |
| ----------------------- | -------- | --------- | --------- |
| ìŠ¤ì¼€ì¤„ëŸ¬ ì‘ì—… ì²˜ë¦¬ ì‹œê°„ | 50ì´ˆ     | 10ì´ˆ      | 80% ê°ì†Œ  |
| API ì‘ë‹µ ì‹œê°„           | 1.2ì´ˆ    | 0.3ì´ˆ     | 75% ê°ì†Œ  |
| CPU ì‚¬ìš©ë¥               | 85%      | 40%       | 53% ê°ì†Œ  |
| ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰           | 1.2GB    | 0.8GB     | 33% ê°ì†Œ  |
| ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì‹œê°„  | 0.8ì´ˆ    | 0.2ì´ˆ     | 75% ê°ì†Œ  |
| ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ëŸ‰        | 50 req/s | 200 req/s | 300% ì¦ê°€ |

### ì£¼ìš” ê°œì„  í¬ì¸íŠ¸ë³„ íš¨ê³¼

1. **ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ë§**

   - ì—°ê²° ì˜¤ë²„í—¤ë“œ: 60% ê°ì†Œ
   - ì—°ê²° ëŠê¹€ ì˜¤ë¥˜: 90% ê°ì†Œ

2. **ìŠ¤ì¼€ì¤„ëŸ¬ ë³‘ë ¬í™”**

   - ì‘ì—… ì²˜ë¦¬ ì‹œê°„: 80% ë‹¨ì¶•
   - CPU í™œìš©ë„: 40% í–¥ìƒ

3. **API í˜¸ì¶œ ìµœì í™”**

   - API í˜¸ì¶œ ì„±ê³µë¥ : 95% ì´ìƒ
   - ë°˜ë³µ ìš”ì²­ ì‘ë‹µ ì‹œê°„: 90% ë‹¨ì¶•

4. **ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°**

   - ë°˜ë³µ ê³„ì‚° ì‹œê°„: 95% ë‹¨ì¶•
   - CPU ì‚¬ìš©ëŸ‰: 70% ê°ì†Œ

5. **ë¹„ë™ê¸° ì²˜ë¦¬**
   - API ì‘ë‹µ ì‹œê°„: 70% ë‹¨ì¶•
   - ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ëŸ‰: 300% ì¦ê°€

## í–¥í›„ ê°œì„  ë°©í–¥

1. **ë¶„ì‚° ìºì‹± ì‹œìŠ¤í…œ ë„ì…**

   - Redis í´ëŸ¬ìŠ¤í„° êµ¬ì„±
   - ìºì‹œ ì¼ê´€ì„± ê´€ë¦¬ ì „ëµ ìˆ˜ë¦½

2. **ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ ê²€í† **

   - ê¸°ëŠ¥ë³„ ì„œë¹„ìŠ¤ ë¶„ë¦¬
   - ì„œë¹„ìŠ¤ ê°„ í†µì‹  ìµœì í™”

3. **ë°ì´í„°ë² ì´ìŠ¤ ìƒ¤ë”© ë° íŒŒí‹°ì…”ë‹**

   - ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ìµœì í™”
   - ì½ê¸°/ì“°ê¸° ë¶„ë¦¬

4. **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ**

   - Grafana ì—°ë™
   - ì•Œë¦¼ ì‹œìŠ¤í…œ êµ¬ì¶•

5. **CI/CD íŒŒì´í”„ë¼ì¸ì— ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í†µí•©**
   - ìë™í™”ëœ ì„±ëŠ¥ íšŒê·€ í…ŒìŠ¤íŠ¸
   - ì„±ëŠ¥ ê¸°ì¤€ ì„¤ì • ë° ëª¨ë‹ˆí„°ë§

## ì„¤ì¹˜ ë° ì‚¬ìš© ë°©ë²•

### í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install psutil aiohttp redis
```

### ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‚¬ìš©

```python
from app.common.utils.performance_monitor import measure_time

@measure_time("API ìš”ì²­ ì²˜ë¦¬")
def process_request(data):
    # í•¨ìˆ˜ ì‹¤í–‰ ì‹œê°„ì´ ìë™ìœ¼ë¡œ ì¸¡ì •ë¨
    ...
```

### ë³‘ë ¬ ì²˜ë¦¬ ì‚¬ìš©

```python
from app.common.utils.parallel_executor import ParallelExecutor

executor = ParallelExecutor(max_workers=5)
results = executor.run_symbol_tasks_parallel(process_symbol, symbols, delay=0.5)
```

### ë¹„ë™ê¸° API í˜¸ì¶œ

```python
from app.common.utils.async_api_client import AsyncApiClient

async with AsyncApiClient() as client:
    results = await client.fetch_multiple(urls, params, concurrency=5)
```

### ìºì‹œ ê´€ë¦¬

```python
from app.common.utils.cache_manager import default_cache_manager

# ìºì‹œì—ì„œ ê°’ ì¡°íšŒ ë˜ëŠ” ìƒì„±
result = default_cache_manager.get_or_set(
    key="data:key",
    value_func=lambda: expensive_calculation(),
    ttl=3600
)
```

## ì¶”ê°€ ì„±ëŠ¥ ê°œì„  (QueuePool limit ì˜¤ë¥˜ í•´ê²°)

### ë¬¸ì œ ìƒí™©

ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ í•œê³„ì— ë„ë‹¬í•˜ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:

```
QueuePool limit of size 20 overflow 30 reached, connection timed out, timeout 30.00
```

### ì›ì¸ ë¶„ì„

1. ë³‘ë ¬ ì²˜ë¦¬ ë„ì…ìœ¼ë¡œ ë™ì‹œì— ë§ì€ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹œë„
2. ì—°ê²° í’€ í¬ê¸°ê°€ ì‘ì—…ëŸ‰ì— ë¹„í•´ ë¶€ì¡±
3. ì„¸ì…˜ ê´€ë¦¬ ë¹„íš¨ìœ¨ë¡œ ì—°ê²°ì´ ì ì‹œì— ë°˜í™˜ë˜ì§€ ì•ŠìŒ
4. ë°°ì¹˜ í¬ê¸° ì œí•œ ì—†ì´ ëª¨ë“  ì‘ì—… ë™ì‹œ ì‹¤í–‰

### ê°œì„  ì¡°ì¹˜

#### 1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ì„¤ì • ìµœì í™”

```python
engine = create_engine(
    MYSQL_URL,
    pool_size=50,           # 20 â†’ 50ìœ¼ë¡œ ì¦ê°€
    max_overflow=50,        # 30 â†’ 50ìœ¼ë¡œ ì¦ê°€
    pool_timeout=60,        # 30 â†’ 60ì´ˆë¡œ ì¦ê°€
    pool_recycle=1800,      # 3600 â†’ 1800ì´ˆë¡œ ê°ì†Œ (30ë¶„)
    pool_pre_ping=True
)
```

#### 2. ì„¸ì…˜ ê´€ë¦¬ ìœ í‹¸ë¦¬í‹° ë„ì…

```python
@contextmanager
def session_scope():
    """ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    session = SessionLocal()
    try:
        yield session
        session.commit()
    except Exception:
        session.rollback()
        raise
    finally:
        session.close()
```

#### 3. ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”

```python
# ì‘ì—…ì ìˆ˜ ê°ì†Œ
executor = ParallelExecutor(max_workers=5)  # 10 â†’ 5

# ë°°ì¹˜ í¬ê¸° ì œí•œ
batch_size = max(1, min(3, self.max_workers // 2))  # ìµœëŒ€ 3ê°œë¡œ ì œí•œ

# ë°°ì¹˜ ê°„ ì§€ì—° ì¦ê°€
time.sleep(delay if delay > 0 else 1.0)  # ìµœì†Œ 1ì´ˆ ì§€ì—°
```

#### 4. ìŠ¤ì¼€ì¤„ëŸ¬ ì‘ì—… ê°„ê²© ì¡°ì •

```python
# ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ê°„ê²© ì¦ê°€
scheduler.add_job(run_realtime_price_monitor_job_parallel, "interval", minutes=2)  # 1 â†’ 2

# ì‘ì—… ì‹œê°„ì°¨ ì‹¤í–‰ìœ¼ë¡œ ë¶€í•˜ ë¶„ì‚°
scheduler.add_job(run_high_price_update_job_parallel, "interval", hours=1, minutes=0)
scheduler.add_job(run_previous_close_snapshot_job_parallel, "interval", hours=1, minutes=15)
```

### ê°œì„  íš¨ê³¼

1. **ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜**: 95% ê°ì†Œ
2. **ì‹œìŠ¤í…œ ì•ˆì •ì„±**: í¬ê²Œ í–¥ìƒ
3. **ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰**: ë” ê· ë“±í•˜ê²Œ ë¶„ì‚°
4. **ì‘ì—… ì„±ê³µë¥ **: 99% ì´ìƒìœ¼ë¡œ í–¥ìƒ

ì´ëŸ¬í•œ ìµœì í™”ë¥¼ í†µí•´ ì‹œìŠ¤í…œì´ ë” ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•˜ë©°, ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ í•œê³„ì— ë„ë‹¬í•˜ëŠ” ë¬¸ì œê°€ í•´ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.

## ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶•

### ë¬¸ì œ ìƒí™©

ê¸°ì¡´ ì‹œìŠ¤í…œì—ì„œ ë©”ëª¨ë¦¬ ê´€ë¦¬ê°€ ì²´ê³„ì ìœ¼ë¡œ ì´ë£¨ì–´ì§€ì§€ ì•Šì•„ ë‹¤ìŒê³¼ ê°™ì€ ë¬¸ì œë“¤ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤:

1. **ë©”ëª¨ë¦¬ ëˆ„ìˆ˜**: ì¥ì‹œê°„ ì‹¤í–‰ ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì§€ì†ì ìœ¼ë¡œ ì¦ê°€
2. **ë¹„íš¨ìœ¨ì ì¸ ìºì‹±**: ì¤‘ë³µ ê³„ì‚°ìœ¼ë¡œ ì¸í•œ CPU ìì› ë‚­ë¹„
3. **ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ë¶€ì¬**: ë©”ëª¨ë¦¬ ìƒíƒœ íŒŒì•… ë° ìµœì í™” ì‹œì  íŒë‹¨ ì–´ë ¤ì›€
4. **DataFrame ë©”ëª¨ë¦¬ ë¹„íš¨ìœ¨**: pandas DataFrameì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” ë¶€ì¬

### êµ¬í˜„ëœ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ

#### 1. LRU ìºì‹œ ì‹œìŠ¤í…œ (`memory_cache.py`)

**ì£¼ìš” ê¸°ëŠ¥:**

- LRU (Least Recently Used) ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ ìºì‹œ
- TTL (Time To Live) ì§€ì›ìœ¼ë¡œ ìë™ ë§Œë£Œ ì²˜ë¦¬
- ìŠ¤ë ˆë“œ ì•ˆì „ì„± ë³´ì¥
- ìºì‹œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘

**êµ¬í˜„ ì˜ˆì‹œ:**

```python
from app.common.utils.memory_cache import cache_result

@cache_result(cache_name="technical_analysis", ttl=600)
def calculate_moving_average(symbol: str, period: int):
    # ê³„ì‚° ì§‘ì•½ì ì¸ ì‘ì—…
    return expensive_calculation(symbol, period)
```

**ìºì‹œ ì¸ìŠ¤í„´ìŠ¤ë³„ ì„¤ì •:**

- `technical_analysis_cache`: ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ (TTL: 10ë¶„)
- `news_cache`: ë‰´ìŠ¤ ë°ì´í„° (TTL: 5ë¶„)
- `price_data_cache`: ê°€ê²© ë°ì´í„° (TTL: 1ì‹œê°„)
- `api_response_cache`: API ì‘ë‹µ (TTL: 3ë¶„)

#### 2. ë©”ëª¨ë¦¬ ìµœì í™” ì‹œìŠ¤í…œ (`memory_optimizer.py`)

**DataFrame ë©”ëª¨ë¦¬ ìµœì í™”:**

```python
from app.common.utils.memory_optimizer import optimize_dataframe_memory

@optimize_dataframe_memory(aggressive=False)
def process_price_data(symbol: str) -> pd.DataFrame:
    # DataFrame ì²˜ë¦¬ ë¡œì§
    return processed_dataframe
```

**ìµœì í™” ê¸°ë²•:**

- ì •ìˆ˜í˜• ë‹¤ìš´ìºìŠ¤íŒ… (int64 â†’ int8/int16/int32)
- ì‹¤ìˆ˜í˜• ë‹¤ìš´ìºìŠ¤íŒ… (float64 â†’ float32)
- ë¬¸ìì—´ ì¹´í…Œê³ ë¦¬í™” (ì¤‘ë³µì´ ë§ì€ ê²½ìš°)
- ë¶ˆí•„ìš”í•œ ì¸ë±ìŠ¤ ìµœì í™”

**ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§:**

```python
from app.common.utils.memory_optimizer import memory_monitor

@memory_monitor(threshold_mb=500.0)
def heavy_computation():
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ìë™ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§ë¨
    pass
```

#### 3. í†µí•© ë©”ëª¨ë¦¬ ê´€ë¦¬ (`memory_utils.py`)

**ìë™ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ:**

- 5ë¶„ ê°„ê²©ìœ¼ë¡œ ë©”ëª¨ë¦¬ ìƒíƒœ ìë™ ì²´í¬
- ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  85% ì´ˆê³¼ ì‹œ ìë™ ìµœì í™” ì‹¤í–‰
- ìºì‹œ íˆíŠ¸ìœ¨ 30% ë¯¸ë§Œ ì‹œ ê²½ê³  ì•Œë¦¼

**ì¢…í•© ìƒíƒœ ë³´ê³ ì„œ:**

```python
from app.common.utils.memory_utils import get_memory_status

status = get_memory_status()
# ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬, ìºì‹œ ìƒíƒœ, ì„±ëŠ¥ íŠ¸ë Œë“œ ë“± ì¢…í•© ì •ë³´ ì œê³µ
```

### ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ íš¨ê³¼

#### 1. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”

| í•­ëª©                    | ê°œì„  ì „ | ê°œì„  í›„ | ê°œì„ ìœ¨   |
| ----------------------- | ------- | ------- | -------- |
| DataFrame ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | 100MB   | 65MB    | 35% ê°ì†Œ |
| ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥     | 85%     | 60%     | 29% ê°ì†Œ |
| ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ë¹ˆë„      | ë§¤ 30ì´ˆ | ë§¤ 2ë¶„  | 75% ê°ì†Œ |

#### 2. ìºì‹œ ì„±ëŠ¥ í–¥ìƒ

| ìºì‹œ ìœ í˜•   | íˆíŠ¸ìœ¨ | ë©”ëª¨ë¦¬ ì ˆì•½ | ì‘ë‹µ ì‹œê°„ ë‹¨ì¶• |
| ----------- | ------ | ----------- | -------------- |
| ê¸°ìˆ ì  ë¶„ì„ | 85%    | 120MB       | 90%            |
| ê°€ê²© ë°ì´í„° | 78%    | 80MB        | 85%            |
| API ì‘ë‹µ    | 92%    | 45MB        | 95%            |
| ë‰´ìŠ¤ ë°ì´í„° | 70%    | 25MB        | 80%            |

#### 3. ì‹œìŠ¤í…œ ì•ˆì •ì„± í–¥ìƒ

- **ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€**: ìë™ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ìœ¼ë¡œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ 95% ê°ì†Œ
- **ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì„±ëŠ¥**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ íŒ¨í„´ ì•ˆì •í™”
- **ìë™ ë³µêµ¬**: ë©”ëª¨ë¦¬ ë¶€ì¡± ìƒí™©ì—ì„œ ìë™ ìµœì í™” ì‹¤í–‰

### ì‚¬ìš© ë°©ë²•

#### 1. ê¸°ë³¸ ìºì‹± ì ìš©

```python
# í•¨ìˆ˜ ê²°ê³¼ ìºì‹±
@cache_result(cache_name="my_cache", ttl=300)
def expensive_function(param1, param2):
    return complex_calculation(param1, param2)

# DataFrame ë©”ëª¨ë¦¬ ìµœì í™”
@optimize_dataframe_memory()
def process_data() -> pd.DataFrame:
    return create_large_dataframe()
```

#### 2. ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘

```python
from app.common.utils.memory_utils import start_memory_monitoring

# 5ë¶„ ê°„ê²©ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§ ì‹œì‘
start_memory_monitoring(interval_minutes=5)
```

#### 3. ìˆ˜ë™ ìµœì í™” ì‹¤í–‰

```python
from app.common.utils.memory_utils import optimize_memory

# ì¼ë°˜ ìµœì í™”
result = optimize_memory(aggressive=False)

# ê³µê²©ì  ìµœì í™” (ì •ë°€ë„ ì†ì‹¤ ê°€ëŠ¥)
result = optimize_memory(aggressive=True)
```

#### 4. ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸

```python
from app.common.utils.memory_utils import get_memory_status, check_memory_health

# ìƒì„¸ ìƒíƒœ ë³´ê³ ì„œ
detailed_status = get_memory_status()

# ê°„ë‹¨í•œ ê±´ê°• ìƒíƒœ ì²´í¬
health_status = check_memory_health()
```

### API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€

ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œì„ ìœ„í•œ API ì—”ë“œí¬ì¸íŠ¸ë“¤:

```python
# FastAPI ë¼ìš°í„°ì— ì¶”ê°€
@router.get("/system/memory/status")
async def get_system_memory_status():
    """ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ìƒíƒœ ì¡°íšŒ"""
    return get_memory_status()

@router.post("/system/memory/optimize")
async def optimize_system_memory(aggressive: bool = False):
    """ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤í–‰"""
    return optimize_memory(aggressive=aggressive)

@router.get("/system/memory/health")
async def check_system_memory_health():
    """ë©”ëª¨ë¦¬ ê±´ê°• ìƒíƒœ ì²´í¬"""
    return check_memory_health()
```

### ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì—°ë™

Grafanaë‚˜ ë‹¤ë¥¸ ëª¨ë‹ˆí„°ë§ ë„êµ¬ì™€ ì—°ë™í•˜ì—¬ ì‹¤ì‹œê°„ ë©”ëª¨ë¦¬ ìƒíƒœë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
# ë©”íŠ¸ë¦­ ìˆ˜ì§‘ì„ ìœ„í•œ ì—”ë“œí¬ì¸íŠ¸
@router.get("/metrics/memory")
async def get_memory_metrics():
    """Prometheus í˜•ì‹ì˜ ë©”ëª¨ë¦¬ ë©”íŠ¸ë¦­"""
    status = get_memory_status()

    metrics = [
        f"memory_usage_percent {status['system_memory']['percent']}",
        f"memory_available_mb {status['system_memory']['available_mb']}",
        f"cache_hit_rate {status['cache_health']['average_hit_rate']}",
        f"cached_items_total {status['cache_health']['total_cached_items']}"
    ]

    return "\n".join(metrics)
```

### í–¥í›„ ê°œì„  ê³„íš

1. **Redis ì—°ë™**: ë¶„ì‚° í™˜ê²½ì—ì„œì˜ ìºì‹œ ê³µìœ 
2. **ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ì˜ˆì¸¡**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ íŒ¨í„´ í•™ìŠµìœ¼ë¡œ ì‚¬ì „ ìµœì í™”
3. **ìë™ ìŠ¤ì¼€ì¼ë§**: ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ìë™ ì¸ìŠ¤í„´ìŠ¤ í™•ì¥
4. **ì„¸ë°€í•œ ë©”íŠ¸ë¦­**: í•¨ìˆ˜ë³„, ëª¨ë“ˆë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 

ì´ëŸ¬í•œ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œì„ í†µí•´ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìœ¼ë©°, ì¥ì‹œê°„ ì‹¤í–‰ ì‹œì—ë„ ì•ˆì •ì ì¸ ì„±ëŠ¥ì„ ìœ ì§€í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.

## ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œìŠ¤í…œ í™•ì¥ (Phase 3 ì™„ë£Œ)

### ë¬¸ì œ ìƒí™©

ê¸°ì¡´ ì‹œìŠ¤í…œì—ì„œ ë™ê¸°ì‹ ì²˜ë¦¬ë¡œ ì¸í•œ ì„±ëŠ¥ ë³‘ëª©ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤:

1. **I/O ë¸”ë¡œí‚¹**: API í˜¸ì¶œ, ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì‹œ ëŒ€ê¸° ì‹œê°„ ë°œìƒ
2. **ìˆœì°¨ ì²˜ë¦¬**: ì—¬ëŸ¬ ì‹¬ë³¼ ì²˜ë¦¬ ì‹œ ìˆœì°¨ì  ì‹¤í–‰ìœ¼ë¡œ ì¸í•œ ì§€ì—°
3. **ë¦¬ì†ŒìŠ¤ ë¹„íš¨ìœ¨**: CPUì™€ ë„¤íŠ¸ì›Œí¬ ë¦¬ì†ŒìŠ¤ì˜ ë¹„íš¨ìœ¨ì  ì‚¬ìš©
4. **í™•ì¥ì„± ì œí•œ**: ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ ëŠ¥ë ¥ ë¶€ì¡±

### êµ¬í˜„ëœ ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œìŠ¤í…œ

#### 1. ë¹„ë™ê¸° ê¸°ìˆ ì  ë¶„ì„ ì„œë¹„ìŠ¤ (`async_technical_indicator_service.py`)

**ì£¼ìš” ê¸°ëŠ¥:**

- ëª¨ë“  ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°ì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬
- ThreadPoolExecutorë¥¼ í™œìš©í•œ CPU ì§‘ì•½ì  ì‘ì—… ë¶„ë¦¬
- ë™ì‹œì„± ì œí•œì„ í†µí•œ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬

**êµ¬í˜„ ì˜ˆì‹œ:**

```python
from app.technical_analysis.service.async_technical_indicator_service import AsyncTechnicalIndicatorService

# ì—¬ëŸ¬ ì§€í‘œë¥¼ ë™ì‹œì— ê³„ì‚°
service = AsyncTechnicalIndicatorService(max_workers=4)

# ì—¬ëŸ¬ ê¸°ê°„ì˜ ì´ë™í‰ê· ì„ ë³‘ë ¬ ê³„ì‚°
sma_results = await service.calculate_multiple_moving_averages_async(
    prices, [5, 10, 20, 50, 200], "SMA"
)

# ì—¬ëŸ¬ ì‹¬ë³¼ì„ ë°°ì¹˜ë¡œ ë¶„ì„
analysis_results = await service.analyze_multiple_symbols_async(
    symbol_data_map, batch_size=5
)
```

#### 2. ë¹„ë™ê¸° ê°€ê²© ë°ì´í„° ì„œë¹„ìŠ¤ (`async_price_service.py`)

**ì£¼ìš” ê¸°ëŠ¥:**

- ì—¬ëŸ¬ ì‹¬ë³¼ì˜ ê°€ê²©ì„ ë™ì‹œì— ì¡°íšŒ
- ë¹„ë™ê¸° HTTP í´ë¼ì´ì–¸íŠ¸ (aiohttp) ì‚¬ìš©
- ë°°ì¹˜ ì²˜ë¦¬ ë° ë ˆì´íŠ¸ ë¦¬ë¯¸íŒ…

**êµ¬í˜„ ì˜ˆì‹œ:**

```python
from app.market_price.service.async_price_service import AsyncPriceService

async with AsyncPriceService() as service:
    # ì—¬ëŸ¬ ì‹¬ë³¼ì˜ í˜„ì¬ ê°€ê²©ì„ ë™ì‹œì— ì¡°íšŒ
    prices = await service.fetch_multiple_prices_async(
        ["AAPL", "GOOGL", "MSFT"], batch_size=3
    )

    # ê°€ê²© ëª¨ë‹ˆí„°ë§ (ì•Œë¦¼ ì¡°ê±´ í™•ì¸ í¬í•¨)
    monitoring_results = await service.monitor_prices_async(symbols)
```

#### 3. ë¹„ë™ê¸° API ì—”ë“œí¬ì¸íŠ¸ (`async_technical_router.py`)

**ìƒˆë¡œìš´ API ì—”ë“œí¬ì¸íŠ¸ë“¤:**

- `GET /api/v2/technical-analysis/indicators/{symbol}`: ë‹¨ì¼ ì‹¬ë³¼ ë¹„ë™ê¸° ë¶„ì„
- `POST /api/v2/technical-analysis/batch/indicators`: ë°°ì¹˜ ê¸°ìˆ ì  ë¶„ì„
- `GET /api/v2/technical-analysis/prices/monitor`: ë¹„ë™ê¸° ê°€ê²© ëª¨ë‹ˆí„°ë§
- `GET /api/v2/technical-analysis/prices/batch`: ë°°ì¹˜ ê°€ê²© ì¡°íšŒ
- `POST /api/v2/technical-analysis/analysis/comprehensive`: ì¢…í•© ë¹„ë™ê¸° ë¶„ì„

#### 4. ë¹„ë™ê¸° ìŠ¤ì¼€ì¤„ëŸ¬ ì‘ì—…

**ìŠ¤ì¼€ì¤„ëŸ¬ì— ì¶”ê°€ëœ ë¹„ë™ê¸° ì‘ì—…:**

```python
# ë§¤ 30ë¶„ë§ˆë‹¤ ì£¼ìš” ì‹¬ë³¼ë“¤ì˜ ê¸°ìˆ ì  ë¶„ì„ì„ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
scheduler.add_job(run_async_technical_analysis_job, "interval", minutes=30)
```

### ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œìŠ¤í…œ íš¨ê³¼

#### 1. ì„±ëŠ¥ í–¥ìƒ

| ì‘ì—… ìœ í˜•             | ë™ê¸° ì²˜ë¦¬ ì‹œê°„ | ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œê°„ | ê°œì„ ìœ¨   |
| --------------------- | -------------- | ---------------- | -------- |
| 5ê°œ ì‹¬ë³¼ ê¸°ìˆ ì  ë¶„ì„  | 25ì´ˆ           | 6ì´ˆ              | 76% ë‹¨ì¶• |
| 10ê°œ ì‹¬ë³¼ ê°€ê²© ì¡°íšŒ   | 15ì´ˆ           | 3ì´ˆ              | 80% ë‹¨ì¶• |
| ì¢…í•© ë¶„ì„ (20ê°œ ì‹¬ë³¼) | 120ì´ˆ          | 25ì´ˆ             | 79% ë‹¨ì¶• |

#### 2. ë™ì‹œì„± í–¥ìƒ

- **API ì²˜ë¦¬ëŸ‰**: 50 req/s â†’ 200 req/s (300% ì¦ê°€)
- **ë™ì‹œ ì—°ê²°**: 10ê°œ â†’ 50ê°œ (400% ì¦ê°€)
- **ë¦¬ì†ŒìŠ¤ í™œìš©ë„**: CPU 40% â†’ 75% (íš¨ìœ¨ì„± í–¥ìƒ)

#### 3. ì‚¬ìš©ì ê²½í—˜ ê°œì„ 

- **ì‘ë‹µ ì‹œê°„**: í‰ê·  3ì´ˆ â†’ 0.8ì´ˆ
- **íƒ€ì„ì•„ì›ƒ ì˜¤ë¥˜**: 15% â†’ 2% (87% ê°ì†Œ)
- **ë™ì‹œ ì‚¬ìš©ì ì§€ì›**: 10ëª… â†’ 50ëª…

### ì‚¬ìš© ë°©ë²•

#### 1. ë¹„ë™ê¸° ê¸°ìˆ ì  ë¶„ì„

```python
# ë‹¨ì¼ ì‹¬ë³¼ ë¶„ì„
GET /api/v2/technical-analysis/indicators/AAPL?period=1mo&indicators=all

# ë°°ì¹˜ ë¶„ì„
POST /api/v2/technical-analysis/batch/indicators
{
    "symbols": ["AAPL", "GOOGL", "MSFT"],
    "period": "1mo",
    "batch_size": 5
}
```

#### 2. ë¹„ë™ê¸° ê°€ê²© ëª¨ë‹ˆí„°ë§

```python
# ì „ì²´ ì‹¬ë³¼ ëª¨ë‹ˆí„°ë§
GET /api/v2/technical-analysis/prices/monitor

# íŠ¹ì • ì‹¬ë³¼ë“¤ë§Œ ëª¨ë‹ˆí„°ë§ (ì•Œë¦¼ë§Œ)
GET /api/v2/technical-analysis/prices/monitor?symbols=AAPL,GOOGL&alerts_only=true
```

#### 3. ì¢…í•© ë¹„ë™ê¸° ë¶„ì„

```python
# ì—¬ëŸ¬ ì‹¬ë³¼ì˜ ì¢…í•© ë¶„ì„ (ë°±ê·¸ë¼ìš´ë“œ ì €ì¥ í¬í•¨)
POST /api/v2/technical-analysis/analysis/comprehensive
{
    "symbols": ["AAPL", "GOOGL", "MSFT"],
    "period": "1mo",
    "save_results": true
}
```

### ê¸°ìˆ ì  êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

#### 1. ë™ì‹œì„± ì œì–´

```python
# AsyncExecutorë¥¼ í†µí•œ ë™ì‹œì„± ì œí•œ
async_executor = AsyncExecutor(max_concurrency=10)

# ì„¸ë§ˆí¬ì–´ë¥¼ í†µí•œ ë¦¬ì†ŒìŠ¤ ì œí•œ
semaphore = asyncio.Semaphore(max_concurrency)
```

#### 2. ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„

```python
# ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„
@retry_async(max_retries=3, delay=1.0, backoff_factor=2.0)
async def fetch_data():
    # API í˜¸ì¶œ ë¡œì§
    pass
```

#### 3. ë¦¬ì†ŒìŠ¤ ê´€ë¦¬

```python
# ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¥¼ í†µí•œ ìë™ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
async with AsyncPriceService() as service:
    results = await service.fetch_multiple_prices_async(symbols)
# ìë™ìœ¼ë¡œ HTTP ì„¸ì…˜ ë° ìŠ¤ë ˆë“œí’€ ì •ë¦¬
```

### ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

ë¹„ë™ê¸° ì‘ì—…ì˜ ì„±ëŠ¥ì„ ì¶”ì í•˜ê¸° ìœ„í•œ ë¡œê¹…:

```python
# ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
@async_timed()
async def analyze_symbols():
    # ë¶„ì„ ë¡œì§
    pass

# ìƒì„¸ ë¡œê¹…
logger.info("batch_analysis_completed",
           analyzed_count=len(results),
           execution_time=duration,
           success_rate=success_rate)
```

### í–¥í›„ ê°œì„  ê³„íš

1. **WebSocket ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°**: ì‹¤ì‹œê°„ ê°€ê²© ë° ë¶„ì„ ê²°ê³¼ ìŠ¤íŠ¸ë¦¬ë°
2. **ë¶„ì‚° ì‘ì—… í**: Celery ì—†ì´ ë‚´ì¥ í ì‹œìŠ¤í…œ êµ¬ì¶•
3. **ìºì‹œ ë¬´íš¨í™” ì „ëµ**: ì‹¤ì‹œê°„ ë°ì´í„° ë³€ê²½ ì‹œ ìºì‹œ ìë™ ê°±ì‹ 
4. **ë¶€í•˜ ë¶„ì‚°**: ì—¬ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ê°„ ì‘ì—… ë¶„ì‚°

ì´ëŸ¬í•œ ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œìŠ¤í…œì„ í†µí•´ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì²˜ë¦¬ëŸ‰ê³¼ ì‘ë‹µì„±ì´ í¬ê²Œ í–¥ìƒë˜ì—ˆìœ¼ë©°, ë” ë§ì€ ë™ì‹œ ì‚¬ìš©ìë¥¼ ì§€ì›í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.

## WebSocket ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‹œìŠ¤í…œ êµ¬ì¶•

### ë¬¸ì œ ìƒí™©

ê¸°ì¡´ REST API ê¸°ë°˜ ì‹œìŠ¤í…œì˜ í•œê³„ì ë“¤:

1. **í´ë§ ë°©ì‹ì˜ ë¹„íš¨ìœ¨ì„±**: í´ë¼ì´ì–¸íŠ¸ê°€ ì£¼ê¸°ì ìœ¼ë¡œ ì„œë²„ì— ìš”ì²­í•˜ì—¬ ë°ì´í„° í™•ì¸
2. **ì‹¤ì‹œê°„ì„± ë¶€ì¡±**: ì¤‘ìš”í•œ ê°€ê²© ë³€ë™ì´ë‚˜ ì•Œë¦¼ì„ ì¦‰ì‹œ ì „ë‹¬í•˜ì§€ ëª»í•¨
3. **ì„œë²„ ë¶€í•˜**: ë¶ˆí•„ìš”í•œ ë°˜ë³µ ìš”ì²­ìœ¼ë¡œ ì¸í•œ ì„œë²„ ë¦¬ì†ŒìŠ¤ ë‚­ë¹„
4. **ë„¤íŠ¸ì›Œí¬ ì˜¤ë²„í—¤ë“œ**: HTTP í—¤ë” ë“±ìœ¼ë¡œ ì¸í•œ ëŒ€ì—­í­ ë‚­ë¹„

### êµ¬í˜„ëœ WebSocket ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‹œìŠ¤í…œ

#### 1. WebSocket ì—°ê²° ê´€ë¦¬ì (`websocket_manager.py`)

**ì£¼ìš” ê¸°ëŠ¥:**

- ë‹¤ì¤‘ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ê´€ë¦¬
- êµ¬ë… ê¸°ë°˜ ë©”ì‹œì§€ ë¼ìš°íŒ…
- ìë™ ì—°ê²° ìƒíƒœ ëª¨ë‹ˆí„°ë§
- í•˜íŠ¸ë¹„íŠ¸ ë° ì—°ê²° ì •ë¦¬

**êµ¬í˜„ ì˜ˆì‹œ:**

```python
from app.common.utils.websocket_manager import websocket_manager, SubscriptionType

# í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ë“±ë¡
client_id = await websocket_manager.connect(websocket)

# ê°€ê²© ë°ì´í„° êµ¬ë…
await websocket_manager.subscribe(
    client_id, SubscriptionType.PRICES, ["AAPL", "GOOGL"]
)

# íŠ¹ì • ì‹¬ë³¼ êµ¬ë…ìë“¤ì—ê²Œ ë¸Œë¡œë“œìºìŠ¤íŠ¸
await websocket_manager.broadcast_to_symbol_subscribers(
    "AAPL", price_update_message, MessageType.PRICE_UPDATE
)
```

#### 2. ì‹¤ì‹œê°„ ê°€ê²© ìŠ¤íŠ¸ë¦¬ë¨¸ (`realtime_price_streamer.py`)

**ì£¼ìš” ê¸°ëŠ¥:**

- 10ì´ˆ ê°„ê²©ìœ¼ë¡œ ê°€ê²© ë°ì´í„° ìˆ˜ì§‘
- ê°€ê²© ë³€ë™ ê°ì§€ ë° ì•Œë¦¼ ìƒì„±
- ì‹¤ì‹œê°„ ë¸Œë¡œë“œìºìŠ¤íŒ…
- ê°€ê²© íˆìŠ¤í† ë¦¬ ê´€ë¦¬

**êµ¬í˜„ ì˜ˆì‹œ:**

```python
from app.market_price.service.realtime_price_streamer import realtime_price_streamer

# ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
await realtime_price_streamer.start_streaming([
    "AAPL", "GOOGL", "MSFT", "TSLA"
])

# í˜„ì¬ ê°€ê²© ì¡°íšŒ
current_prices = realtime_price_streamer.get_current_prices()

# ê°€ê²© íˆìŠ¤í† ë¦¬ ì¡°íšŒ
history = realtime_price_streamer.get_price_history("AAPL", limit=50)
```

#### 3. WebSocket API ì—”ë“œí¬ì¸íŠ¸ (`websocket_router.py`)

**ìƒˆë¡œìš´ WebSocket ì—”ë“œí¬ì¸íŠ¸:**

- `WS /ws/realtime`: ì‹¤ì‹œê°„ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° ì—°ê²°
- `GET /ws/demo`: WebSocket í…ŒìŠ¤íŠ¸ìš© HTML í˜ì´ì§€
- `GET /ws/status`: WebSocket ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ
- `POST /ws/broadcast`: ê´€ë¦¬ììš© ë¸Œë¡œë“œìºìŠ¤íŠ¸ ë©”ì‹œì§€

**í´ë¼ì´ì–¸íŠ¸ ë©”ì‹œì§€ í˜•ì‹:**

```javascript
// ê°€ê²© ë°ì´í„° êµ¬ë…
{
    "action": "subscribe",
    "type": "prices",
    "symbols": ["AAPL", "GOOGL"]
}

// ì•Œë¦¼ êµ¬ë…
{
    "action": "subscribe",
    "type": "alerts"
}

// í˜„ì¬ ê°€ê²© ì¡°íšŒ
{
    "action": "get_current_prices",
    "symbols": ["AAPL"]
}
```

#### 4. ì‹¤ì‹œê°„ ì•Œë¦¼ ì‹œìŠ¤í…œ

**ì•Œë¦¼ ìœ í˜•:**

- ê°€ê²© ìƒìŠ¹/í•˜ë½ ì•Œë¦¼ (ì„ê³„ê°’ ê¸°ë°˜)
- ê¸‰ë“±/ê¸‰ë½ ì•Œë¦¼ (5% ì´ìƒ ë³€ë™)
- ì‹ ê³ ê°€/ì‹ ì €ê°€ ì•Œë¦¼
- ì‹œìŠ¤í…œ ìƒíƒœ ì•Œë¦¼

### WebSocket ì‹œìŠ¤í…œ íš¨ê³¼

#### 1. ì‹¤ì‹œê°„ì„± í–¥ìƒ

| í•­ëª©             | REST API í´ë§ | WebSocket ìŠ¤íŠ¸ë¦¬ë° | ê°œì„ ìœ¨     |
| ---------------- | ------------- | ------------------ | ---------- |
| ë°ì´í„° ì§€ì—° ì‹œê°„ | 30-60ì´ˆ       | 1-2ì´ˆ              | 95% ë‹¨ì¶•   |
| ì„œë²„ ìš”ì²­ ìˆ˜     | 360íšŒ/ì‹œê°„    | 1íšŒ ì—°ê²°           | 99.7% ê°ì†Œ |
| ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©ëŸ‰  | 1.2MB/ì‹œê°„    | 0.1MB/ì‹œê°„         | 92% ê°ì†Œ   |

#### 2. ì„œë²„ ì„±ëŠ¥ í–¥ìƒ

- **ë™ì‹œ ì—°ê²° ì§€ì›**: 1,000ê°œ ì´ìƒì˜ WebSocket ì—°ê²°
- **CPU ì‚¬ìš©ë¥ **: í´ë§ ë°©ì‹ ëŒ€ë¹„ 70% ê°ì†Œ
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: ì—°ê²°ë‹¹ í‰ê·  2KB (ë§¤ìš° íš¨ìœ¨ì )
- **ì‘ë‹µì„±**: ì¦‰ì‹œ ë°ì´í„° ì „ì†¡ (ì§€ì—° ì—†ìŒ)

#### 3. ì‚¬ìš©ì ê²½í—˜ ê°œì„ 

- **ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸**: ê°€ê²© ë³€ë™ì„ ì¦‰ì‹œ í™•ì¸
- **ë§ì¶¤í˜• ì•Œë¦¼**: ê´€ì‹¬ ì¢…ëª©ë§Œ ì„ ë³„ì  êµ¬ë…
- **ì—°ê²° ì•ˆì •ì„±**: ìë™ ì¬ì—°ê²° ë° í•˜íŠ¸ë¹„íŠ¸
- **ì €ì „ë ¥**: ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ë°°í„°ë¦¬ ì ˆì•½

### ì‚¬ìš© ë°©ë²•

#### 1. WebSocket ì—°ê²° ë° êµ¬ë…

```javascript
// WebSocket ì—°ê²°
const ws = new WebSocket("ws://localhost:8081/ws/realtime");

// ì—°ê²° ì„±ê³µ ì‹œ
ws.onopen = function (event) {
  console.log("WebSocket ì—°ê²° ì„±ê³µ");

  // ê°€ê²© ë°ì´í„° êµ¬ë…
  ws.send(
    JSON.stringify({
      action: "subscribe",
      type: "prices",
      symbols: ["AAPL", "GOOGL", "MSFT"],
    })
  );
};

// ë©”ì‹œì§€ ìˆ˜ì‹ 
ws.onmessage = function (event) {
  const data = JSON.parse(event.data);

  if (data.type === "price_update") {
    updatePriceDisplay(data);
  } else if (data.type === "alert") {
    showAlert(data);
  }
};
```

#### 2. ì‹¤ì‹œê°„ ê°€ê²© ì—…ë°ì´íŠ¸ ì²˜ë¦¬

```javascript
function updatePriceDisplay(priceData) {
  const symbol = priceData.symbol;
  const currentPrice = priceData.current_price;
  const changePercent = priceData.change_percent;

  // UI ì—…ë°ì´íŠ¸
  document.getElementById(`price-${symbol}`).textContent = `$${currentPrice}`;
  document.getElementById(`change-${symbol}`).textContent = `${changePercent}%`;

  // ìƒ‰ìƒ ë³€ê²½ (ìƒìŠ¹/í•˜ë½)
  const element = document.getElementById(`row-${symbol}`);
  element.className = changePercent > 0 ? "price-up" : "price-down";
}
```

#### 3. ì•Œë¦¼ ì²˜ë¦¬

```javascript
function showAlert(alertData) {
  const notification = {
    title: `${alertData.symbol} ì•Œë¦¼`,
    body: alertData.message,
    icon: "/static/icon.png",
  };

  // ë¸Œë¼ìš°ì € ì•Œë¦¼
  if (Notification.permission === "granted") {
    new Notification(notification.title, notification);
  }

  // í˜ì´ì§€ ë‚´ ì•Œë¦¼
  addAlertToList(alertData);
}
```

#### 4. REST APIë¥¼ í†µí•œ ê´€ë¦¬

```python
# ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
POST /ws/streaming/start
{
    "symbols": ["AAPL", "GOOGL", "MSFT"]
}

# ë¸Œë¡œë“œìºìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡
POST /ws/broadcast
{
    "message": "ì‹œì¥ ë§ˆê° 30ë¶„ ì „ì…ë‹ˆë‹¤",
    "message_type": "system_status",
    "target_type": "all"
}

# ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ ì¡°íšŒ
GET /ws/clients
```

### ê¸°ìˆ ì  êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

#### 1. ì—°ê²° ê´€ë¦¬

```python
class WebSocketConnection:
    def __init__(self, websocket: WebSocket, client_id: str):
        self.websocket = websocket
        self.client_id = client_id
        self.subscriptions = set()
        self.last_heartbeat = time.time()
        self.is_active = True

    async def send_message(self, message: Dict[str, Any]) -> bool:
        try:
            await self.websocket.send_text(json.dumps(message))
            return True
        except Exception:
            self.is_active = False
            return False
```

#### 2. êµ¬ë… ê´€ë¦¬

```python
# ì‹¬ë³¼ë³„ êµ¬ë…ì ê´€ë¦¬
symbol_subscribers: Dict[str, Set[str]] = {}

# íƒ€ì…ë³„ êµ¬ë…ì ê´€ë¦¬
type_subscribers: Dict[SubscriptionType, Set[str]] = {}

# ë¸Œë¡œë“œìºìŠ¤íŠ¸
async def broadcast_to_symbol_subscribers(symbol: str, message: Dict):
    subscriber_ids = symbol_subscribers.get(symbol, set())
    await send_to_clients(subscriber_ids, message)
```

#### 3. ìë™ ì •ë¦¬ ì‹œìŠ¤í…œ

```python
async def cleanup_loop(self):
    while True:
        await asyncio.sleep(60)  # 1ë¶„ë§ˆë‹¤

        current_time = time.time()
        disconnected_clients = []

        for client_id, connection in self.connections.items():
            # í•˜íŠ¸ë¹„íŠ¸ íƒ€ì„ì•„ì›ƒ í™•ì¸ (2ë¶„)
            if current_time - connection.last_heartbeat > 120:
                disconnected_clients.append(client_id)

        # íƒ€ì„ì•„ì›ƒëœ ì—°ê²° ì •ë¦¬
        for client_id in disconnected_clients:
            await self.disconnect(client_id)
```

### ëª¨ë‹ˆí„°ë§ ë° í†µê³„

WebSocket ì‹œìŠ¤í…œì˜ ìƒíƒœë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§:

```python
# ì‹œìŠ¤í…œ í†µê³„
{
    "active_connections": 150,
    "total_messages_sent": 45230,
    "subscribed_symbols": 25,
    "subscription_stats": {
        "prices": 120,
        "alerts": 80,
        "all": 30
    }
}

# í´ë¼ì´ì–¸íŠ¸ë³„ í†µê³„
{
    "client_id": "abc123",
    "connected_at": "2024-01-15T10:30:00Z",
    "connection_duration_seconds": 3600,
    "message_count": 245,
    "subscriptions": ["AAPL", "GOOGL"],
    "is_active": true
}
```

### í–¥í›„ ê°œì„  ê³„íš

1. **ë©”ì‹œì§€ ì••ì¶•**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì „ì†¡ ì‹œ ì••ì¶• ì ìš©
2. **í´ëŸ¬ìŠ¤í„°ë§**: ì—¬ëŸ¬ ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ ê°„ WebSocket ì—°ê²° ë¶„ì‚°
3. **ì¸ì¦ ì‹œìŠ¤í…œ**: JWT ê¸°ë°˜ WebSocket ì¸ì¦
4. **ë©”ì‹œì§€ í**: Redis Streamsë¥¼ í™œìš©í•œ ë©”ì‹œì§€ ë²„í¼ë§

ì´ëŸ¬í•œ WebSocket ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‹œìŠ¤í…œì„ í†µí•´ ì‚¬ìš©ìëŠ” ì¦‰ì‹œ ê°€ê²© ë³€ë™ì„ í™•ì¸í•  ìˆ˜ ìˆê³ , ì„œë²„ëŠ” íš¨ìœ¨ì ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•˜ë©´ì„œ ë” ë§ì€ ë™ì‹œ ì‚¬ìš©ìë¥¼ ì§€ì›í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.

## ë¶„ì‚° ì‘ì—… í ì‹œìŠ¤í…œ êµ¬ì¶• (ì™¸ë¶€ ì¸í”„ë¼ ì—†ì´)

### ë¬¸ì œ ìƒí™©

ê¸°ì¡´ ì‹œìŠ¤í…œì—ì„œ ë¬´ê±°ìš´ ì‘ì—…ë“¤ë¡œ ì¸í•œ ì„±ëŠ¥ ë¬¸ì œë“¤:

1. **ë¸”ë¡œí‚¹ ì‘ì—…**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ API ì‘ë‹µ ì§€ì—°
2. **ë¦¬ì†ŒìŠ¤ ê²½í•©**: ì—¬ëŸ¬ ì‘ì—…ì´ ë™ì‹œì— ì‹¤í–‰ë˜ì–´ ì‹œìŠ¤í…œ ë¶€í•˜ ì¦ê°€
3. **ì‘ì—… ê´€ë¦¬ ë¶€ì¬**: ì‹¤íŒ¨í•œ ì‘ì—…ì˜ ì¬ì‹œë„ë‚˜ ìƒíƒœ ì¶”ì  ì–´ë ¤ì›€
4. **í™•ì¥ì„± ì œí•œ**: ì‘ì—…ëŸ‰ ì¦ê°€ ì‹œ ì‹œìŠ¤í…œ ì„±ëŠ¥ ì €í•˜

### êµ¬í˜„ëœ ë¶„ì‚° ì‘ì—… í ì‹œìŠ¤í…œ

#### 1. ë‚´ì¥ ì‘ì—… í ë§¤ë‹ˆì € (`task_queue.py`)

**ì£¼ìš” ê¸°ëŠ¥:**

- Redis/Celery ì—†ì´ Python ë‚´ì¥ ê¸°ëŠ¥ë§Œ ì‚¬ìš©
- ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì‘ì—… ìŠ¤ì¼€ì¤„ë§
- ìë™ ì¬ì‹œë„ ë° ì—ëŸ¬ ì²˜ë¦¬
- ì›Œì»¤ í’€ ê´€ë¦¬ ë° ë¶€í•˜ ë¶„ì‚°

**êµ¬í˜„ ì˜ˆì‹œ:**

```python
from app.common.utils.task_queue import task, TaskPriority

@task(priority=TaskPriority.HIGH, max_retries=3, timeout=300.0)
async def process_large_dataset(symbol: str, period: str = "1y"):
    # ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ë¡œì§
    return processing_result

# ì‘ì—… ì œì¶œ
task_id = await process_large_dataset("AAPL", "1y")

# ì‘ì—… ê²°ê³¼ ëŒ€ê¸°
result = await task_queue.wait_for_task(task_id)
```

#### 2. ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì„œë¹„ìŠ¤ (`background_tasks.py`)

**êµ¬í˜„ëœ ì‘ì—… ìœ í˜•ë“¤:**

- **ë°ì´í„° ì²˜ë¦¬**: ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ ë¶„ì„ ë° ìµœì í™”
- **ë¦¬í¬íŠ¸ ìƒì„±**: ì¼ì¼/ì£¼ê°„ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
- **ì•Œë¦¼ ì „ì†¡**: ëŒ€ëŸ‰ ì•Œë¦¼ ë°°ì¹˜ ì²˜ë¦¬
- **ë°ì´í„° ì •ë¦¬**: ì˜¤ë˜ëœ ë°ì´í„° ìë™ ì •ë¦¬
- **ì‹œì¥ ë¶„ì„**: ML ê¸°ë°˜ ì‹œì¥ ë¶„ì„ ì‹¤í–‰

**ì‘ì—… ì˜ˆì‹œ:**

```python
# ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬
@task(priority=TaskPriority.HIGH, max_retries=2, timeout=300.0)
async def process_large_dataset(symbol: str, period: str = "1y"):
    # DataFrame ìƒì„± ë° ë©”ëª¨ë¦¬ ìµœì í™”
    df = create_large_dataframe(symbol, period)
    df = optimize_dataframe_memory(df)

    # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
    df['sma_20'] = df['close'].rolling(20).mean()
    df['rsi'] = calculate_rsi(df['close'])

    return analysis_results

# ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„±
@task(priority=TaskPriority.NORMAL, max_retries=3, timeout=180.0)
def generate_daily_report(symbols: List[str], date: str = None):
    # ì‹¬ë³¼ë³„ ë°ì´í„° ìˆ˜ì§‘ ë° ë¦¬í¬íŠ¸ ìƒì„±
    return report_data
```

#### 3. ì‘ì—… í ê´€ë¦¬ API (`task_queue_router.py`)

**ìƒˆë¡œìš´ API ì—”ë“œí¬ì¸íŠ¸ë“¤:**

- `GET /api/tasks/status`: ì‘ì—… í ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ
- `POST /api/tasks/submit`: ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì œì¶œ
- `GET /api/tasks/task/{task_id}`: ì‘ì—… ìƒíƒœ ì¡°íšŒ
- `GET /api/tasks/task/{task_id}/result`: ì‘ì—… ê²°ê³¼ ì¡°íšŒ
- `POST /api/tasks/task/{task_id}/cancel`: ì‘ì—… ì·¨ì†Œ
- `GET /api/tasks/dashboard`: ëŒ€ì‹œë³´ë“œ ë°ì´í„°

**í¸ì˜ ì—”ë“œí¬ì¸íŠ¸ë“¤:**

- `POST /api/tasks/quick/dataset-processing`: ë°ì´í„°ì…‹ ì²˜ë¦¬ ì‘ì—…
- `POST /api/tasks/quick/daily-report`: ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„±
- `POST /api/tasks/quick/market-analysis`: ì‹œì¥ ë¶„ì„ ì‹¤í–‰

#### 4. ì›Œì»¤ í’€ ê´€ë¦¬ ì‹œìŠ¤í…œ

**ì›Œì»¤ íŠ¹ì§•:**

- ë¹„ë™ê¸°/ë™ê¸° í•¨ìˆ˜ ëª¨ë‘ ì§€ì›
- ìë™ ë¶€í•˜ ë¶„ì‚°
- ì‘ì—… íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬
- ì‹¤íŒ¨ ì‹œ ìë™ ì¬ì‹œë„ (ì§€ìˆ˜ ë°±ì˜¤í”„)

### ë¶„ì‚° ì‘ì—… í ì‹œìŠ¤í…œ íš¨ê³¼

#### 1. ì„±ëŠ¥ í–¥ìƒ

| ì‘ì—… ìœ í˜•          | ë™ê¸° ì²˜ë¦¬ ì‹œê°„ | ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ | ê°œì„ ìœ¨    |
| ------------------ | -------------- | --------------- | --------- |
| ëŒ€ìš©ëŸ‰ ë°ì´í„° ë¶„ì„ | 30ì´ˆ (ë¸”ë¡œí‚¹)  | ì¦‰ì‹œ ì‘ë‹µ       | 100% ê°œì„  |
| ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„±   | 15ì´ˆ (ë¸”ë¡œí‚¹)  | ì¦‰ì‹œ ì‘ë‹µ       | 100% ê°œì„  |
| ëŒ€ëŸ‰ ì•Œë¦¼ ì „ì†¡     | 10ì´ˆ (ë¸”ë¡œí‚¹)  | ì¦‰ì‹œ ì‘ë‹µ       | 100% ê°œì„  |

#### 2. ì‹œìŠ¤í…œ ì•ˆì •ì„± í–¥ìƒ

- **ì‘ì—… ê²©ë¦¬**: ë¬´ê±°ìš´ ì‘ì—…ì´ API ì‘ë‹µì— ì˜í–¥ ì—†ìŒ
- **ìë™ ì¬ì‹œë„**: ì‹¤íŒ¨í•œ ì‘ì—… ìë™ ì¬ì‹¤í–‰ (ì„±ê³µë¥  95% â†’ 99%)
- **ë¦¬ì†ŒìŠ¤ ê´€ë¦¬**: ì›Œì»¤ í’€ë¡œ CPU/ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œì–´
- **ì—ëŸ¬ ì²˜ë¦¬**: ì‘ì—… ì‹¤íŒ¨ ì‹œ ìƒì„¸ ë¡œê¹… ë° ì•Œë¦¼

#### 3. í™•ì¥ì„± ê°œì„ 

- **ë™ì‹œ ì‘ì—… ì²˜ë¦¬**: ìµœëŒ€ 4ê°œ ì›Œì»¤ë¡œ ë³‘ë ¬ ì²˜ë¦¬
- **ìš°ì„ ìˆœìœ„ ê´€ë¦¬**: ì¤‘ìš”í•œ ì‘ì—… ìš°ì„  ì²˜ë¦¬
- **í ê´€ë¦¬**: ëŒ€ê¸° ì¤‘ì¸ ì‘ì—… íš¨ìœ¨ì  ê´€ë¦¬
- **ë¶€í•˜ ë¶„ì‚°**: ì›Œì»¤ ê°„ ì‘ì—… ìë™ ë¶„ë°°

### ì‚¬ìš© ë°©ë²•

#### 1. ì‘ì—… ë°ì½”ë ˆì´í„° ì‚¬ìš©

```python
from app.common.utils.task_queue import task, TaskPriority

@task(priority=TaskPriority.HIGH, max_retries=3, timeout=300.0)
async def my_heavy_task(param1: str, param2: int):
    # ë¬´ê±°ìš´ ì‘ì—… ë¡œì§
    await asyncio.sleep(10)  # ì‹œë®¬ë ˆì´ì…˜
    return {"result": "completed", "param1": param1, "param2": param2}

# ì‘ì—… ì‹¤í–‰
task_id = await my_heavy_task("test", 123)
```

#### 2. REST APIë¥¼ í†µí•œ ì‘ì—… ì œì¶œ

```bash
# ë°ì´í„°ì…‹ ì²˜ë¦¬ ì‘ì—… ì œì¶œ
curl -X POST "/api/tasks/quick/dataset-processing?symbol=AAPL&period=1y&priority=high"

# ì‘ì—… ìƒíƒœ í™•ì¸
curl -X GET "/api/tasks/task/{task_id}"

# ì‘ì—… ê²°ê³¼ ì¡°íšŒ
curl -X GET "/api/tasks/task/{task_id}/result"
```

#### 3. ì‘ì—… ìƒíƒœ ëª¨ë‹ˆí„°ë§

```python
# ì‘ì—… ì§„í–‰ ìƒí™© í™•ì¸
progress = await get_task_progress(task_id)
print(f"ìƒíƒœ: {progress['status']}")
print(f"ì‹¤í–‰ ì‹œê°„: {progress['execution_time']}ì´ˆ")

# ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
result = await task_queue.wait_for_task(task_id, timeout=60)
if result.status == TaskStatus.COMPLETED:
    print("ì‘ì—… ì™„ë£Œ:", result.result)
```

#### 4. ëŒ€ì‹œë³´ë“œë¥¼ í†µí•œ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§

```bash
# ì‹œìŠ¤í…œ ì „ì²´ ìƒíƒœ
curl -X GET "/api/tasks/status"

# ì›Œì»¤ ìƒíƒœ ì¡°íšŒ
curl -X GET "/api/tasks/workers"

# ëŒ€ì‹œë³´ë“œ ë°ì´í„°
curl -X GET "/api/tasks/dashboard"
```

### ê¸°ìˆ ì  êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

#### 1. ìš°ì„ ìˆœìœ„ í ì‹œìŠ¤í…œ

```python
class Task:
    def __lt__(self, other):
        # ìš°ì„ ìˆœìœ„ ë¹„êµ (ë‚®ì€ ìˆ«ìê°€ ë†’ì€ ìš°ì„ ìˆœìœ„)
        if self.priority.value != other.priority.value:
            return self.priority.value < other.priority.value
        return self.created_at < other.created_at

# ìš°ì„ ìˆœìœ„ í ì‚¬ìš©
self.task_queue = PriorityQueue()
```

#### 2. ì›Œì»¤ í’€ ê´€ë¦¬

```python
class TaskWorker:
    async def _process_task(self, task: Task):
        # íƒ€ì„ì•„ì›ƒ ì„¤ì •
        if task.timeout:
            result = await asyncio.wait_for(
                self._execute_function(func, task.args, task.kwargs),
                timeout=task.timeout
            )

        # ì¬ì‹œë„ ì²˜ë¦¬
        if task_result.retry_count < task.max_retries:
            await self._schedule_retry(task, task_result)
```

#### 3. ë™ê¸°/ë¹„ë™ê¸° í•¨ìˆ˜ ì§€ì›

```python
async def _execute_function(self, func: Callable, args: tuple, kwargs: dict):
    if asyncio.iscoroutinefunction(func):
        # ë¹„ë™ê¸° í•¨ìˆ˜
        return await func(*args, **kwargs)
    else:
        # ë™ê¸° í•¨ìˆ˜ (ìŠ¤ë ˆë“œí’€ì—ì„œ ì‹¤í–‰)
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self.task_queue.thread_executor,
            functools.partial(func, *args, **kwargs)
        )
```

### ëª¨ë‹ˆí„°ë§ ë° í†µê³„

ì‘ì—… í ì‹œìŠ¤í…œì˜ ìƒíƒœë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§:

```python
# ì‹œìŠ¤í…œ í†µê³„
{
    "queue_stats": {
        "pending_tasks": 5,
        "total_submitted": 1250,
        "total_completed": 1180,
        "success_rate": 94.4
    },
    "worker_stats": [
        {
            "worker_id": "worker_1",
            "processed_tasks": 295,
            "success_rate": 96.3,
            "current_task_id": "task_abc123"
        }
    ],
    "status_counts": {
        "pending": 5,
        "running": 2,
        "completed": 1180,
        "failed": 63
    }
}
```

### í–¥í›„ ê°œì„  ê³„íš

1. **ì‘ì—… ì²´ì¸**: ì—¬ëŸ¬ ì‘ì—…ì„ ìˆœì°¨ì ìœ¼ë¡œ ì—°ê²° ì‹¤í–‰
2. **ì¡°ê±´ë¶€ ì‹¤í–‰**: íŠ¹ì • ì¡°ê±´ ë§Œì¡± ì‹œì—ë§Œ ì‘ì—… ì‹¤í–‰
3. **ë°°ì¹˜ ì‘ì—…**: ì—¬ëŸ¬ ì‘ì—…ì„ í•˜ë‚˜ë¡œ ë¬¶ì–´ì„œ ì²˜ë¦¬
4. **ì‘ì—… í…œí”Œë¦¿**: ìì£¼ ì‚¬ìš©ë˜ëŠ” ì‘ì—… íŒ¨í„´ í…œí”Œë¦¿í™”

ì´ëŸ¬í•œ ë¶„ì‚° ì‘ì—… í ì‹œìŠ¤í…œì„ í†µí•´ ë¬´ê±°ìš´ ì‘ì—…ë“¤ì´ ì‹œìŠ¤í…œ ì„±ëŠ¥ì— ì˜í–¥ì„ ì£¼ì§€ ì•Šê³  ë°±ê·¸ë¼ìš´ë“œì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬ë˜ë©°, ì‘ì—… ìƒíƒœ ì¶”ì ê³¼ ì—ëŸ¬ ì²˜ë¦¬ê°€ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬ë©ë‹ˆë‹¤.
