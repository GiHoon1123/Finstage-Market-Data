# Finstage Market Data - ë°±ì—”ë“œ ì•„í‚¤í…ì²˜ ë° ê¸°ìˆ  êµ¬í˜„

## 1. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ê°œìš”

### í•µì‹¬ ì„¤ê³„ ì² í•™

Finstage Market Data ë°±ì—”ë“œëŠ” **"ëª¨ë“ˆë³„ ì±…ì„ ë¶„ë¦¬ë¥¼ í†µí•œ í™•ì¥ ê°€ëŠ¥í•œ ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬"**ë¥¼ ëª©í‘œë¡œ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ê° ëª¨ë“ˆì€ ëª…í™•í•œ ì—­í• ì„ ê°€ì§€ë©°, APScheduler ê¸°ë°˜ ìŠ¤ì¼€ì¤„ë§ì„ í†µí•´ ì •ì‹œ ì‘ì—… ì‹¤í–‰ê³¼ ì‹œìŠ¤í…œ ì•ˆì •ì„±ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤.

### ëª¨ë“ˆ êµ¬ì¡° ë° ì±…ì„ ë¶„ë¦¬

```
app/
â”œâ”€â”€ news_crawler/           # ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹œìŠ¤í…œ
â”œâ”€â”€ technical_analysis/     # ê¸°ìˆ ì  ë¶„ì„ ì—”ì§„
â”œâ”€â”€ market_price/          # ê°€ê²© ë°ì´í„° ì²˜ë¦¬
â”œâ”€â”€ message_notification/   # í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì‹œìŠ¤í…œ
â”œâ”€â”€ scheduler/             # ì‘ì—… ìŠ¤ì¼€ì¤„ë§
â”œâ”€â”€ common/                # ê³µí†µ ìœ í‹¸ë¦¬í‹°
â”‚   â”œâ”€â”€ utils/            # ë³‘ë ¬ ì²˜ë¦¬, ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸
â”‚   â””â”€â”€ infra/            # ë°ì´í„°ë² ì´ìŠ¤, ì„¤ì •
â””â”€â”€ company/              # ê¸°ì—… ì •ë³´ ê´€ë¦¬
```

ê° ëª¨ë“ˆì€ ë…ë¦½ì ì¸ ì±…ì„ì„ ê°€ì§€ë©°, ì§ì ‘ì ì¸ í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±ê³¼ ë©”ì„œë“œ í˜¸ì¶œì„ í†µí•´ ë™ì‘í•©ë‹ˆë‹¤.

### ìŠ¤ì¼€ì¤„ëŸ¬ ê¸°ë°˜ ì‘ì—… íë¦„

```python
# APSchedulerë¥¼ í†µí•œ ì •ì‹œ ì‘ì—… ì‹¤í–‰
Scheduler â†’ ë‰´ìŠ¤ í¬ë¡¤ë§ â†’ ê¸°ìˆ ì  ë¶„ì„ â†’ ì‹ í˜¸ ìƒì„± â†’ í…”ë ˆê·¸ë¨ ì•Œë¦¼
```

**êµ¬í˜„ëœ ì£¼ìš” ì‘ì—… íë¦„:**

- **ë‰´ìŠ¤ í¬ë¡¤ë§**: 1ì‹œê°„ë§ˆë‹¤ ë‹¤ì¤‘ ì†ŒìŠ¤ì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘
- **ê¸°ìˆ ì  ë¶„ì„**: ì‹¤ì‹œê°„ ê°€ê²© ë°ì´í„° ê¸°ë°˜ ì‹ í˜¸ ìƒì„±
- **ë°±í…ŒìŠ¤íŒ…**: ê³¼ê±° ë°ì´í„°ë¡œ ì „ëµ ì„±ê³¼ ê²€ì¦
- **ì•Œë¦¼ ì „ì†¡**: í…”ë ˆê·¸ë¨ì„ í†µí•œ ì‹¤ì‹œê°„ ì‹ í˜¸ ì „ë‹¬

**ìŠ¤ì¼€ì¤„ëŸ¬ ê¸°ë°˜ ì„¤ê³„ì˜ ì‹¤ì œ íš¨ê³¼:**

- **ì •ì‹œ ì‹¤í–‰**: ì •í•´ì§„ ì‹œê°„ì— ì•ˆì •ì ìœ¼ë¡œ ì‘ì—… ìˆ˜í–‰
- **ë…ë¦½ì  ëª¨ë“ˆ**: ê° ì‘ì—…ì´ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ë˜ì–´ ì¥ì•  ê²©ë¦¬
- **í™•ì¥ ìš©ì´ì„±**: ìƒˆë¡œìš´ ì‘ì—… ì¶”ê°€ ì‹œ ìŠ¤ì¼€ì¤„ëŸ¬ì— ë“±ë¡ë§Œ í•˜ë©´ ë¨

## 2. ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œ

### ë³‘ë ¬ ì²˜ë¦¬ ì—”ì§„ êµ¬í˜„

**ParallelExecutor í´ë˜ìŠ¤**

```python
class ParallelExecutor:
    """ë³‘ë ¬ ì‘ì—… ì‹¤í–‰ì„ ìœ„í•œ í´ë˜ìŠ¤"""

    def __init__(self, max_workers: int = 5):
        self.max_workers = max_workers

    def run_symbol_tasks_parallel(
        self, func: Callable, symbols: List[str], delay: float = 0
    ) -> List[Any]:
        """
        ì‹¬ë³¼ë³„ ì‘ì—…ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰ (API ì œí•œ ê³ ë ¤)

        Args:
            func: ì‹¤í–‰í•  í•¨ìˆ˜
            symbols: ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸
            delay: ê° ì‘ì—… ê°„ ì§€ì—° ì‹œê°„ (ì´ˆ)
        """
        # ë°°ì¹˜ í¬ê¸° ì œí•œìœ¼ë¡œ DB ì—°ê²° ë¶€í•˜ ê°ì†Œ
        batch_size = 1  # ìˆœì°¨ ì²˜ë¦¬ë¡œ ì•ˆì •ì„± í™•ë³´
        results = []

        for i, symbol in enumerate(symbols):
            try:
                result = func(symbol)
                results.append(result)
            except Exception as e:
                print(f"âŒ {symbol} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                results.append(None)

            # API ì œí•œ ê³ ë ¤í•œ ì§€ì—° ì‹œê°„
            if i < len(symbols) - 1:
                sleep_time = delay if delay > 0 else 5.0
                time.sleep(sleep_time)

        return results
```

**ì„±ëŠ¥ ìµœì í™” íŠ¹ì§•:**

- **ë°°ì¹˜ ì²˜ë¦¬**: ëŒ€ëŸ‰ ë°ì´í„°ë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
- **ì§€ì—° ì œì–´**: API ì œí•œì„ ê³ ë ¤í•œ ì§€ëŠ¥ì  ìš”ì²­ ìŠ¤ì¼€ì¤„ë§
- **ì—ëŸ¬ ê²©ë¦¬**: ê°œë³„ ì‘ì—… ì‹¤íŒ¨ê°€ ì „ì²´ í”„ë¡œì„¸ìŠ¤ì— ì˜í–¥ ì£¼ì§€ ì•ŠìŒ

### ë¹„ë™ê¸° API í´ë¼ì´ì–¸íŠ¸

**AsyncApiClient êµ¬í˜„**

```python
class AsyncApiClient:
    """ë¹„ë™ê¸° API í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self, base_url: str = "", timeout: int = 30):
        self.base_url = base_url
        self.timeout = aiohttp.ClientTimeout(total=timeout)
        self.session = None
        self.rate_limit_delay = 0.5  # ê¸°ë³¸ ìš”ì²­ ê°„ê²©

    async def fetch_multiple(
        self,
        urls: List[str],
        params: Dict = None,
        concurrency: int = 5,
        delay: float = 0.5,
    ) -> List[Any]:
        """
        ì—¬ëŸ¬ URLì„ ë³‘ë ¬ë¡œ ìš”ì²­

        Args:
            urls: ìš”ì²­í•  URL ëª©ë¡
            concurrency: ìµœëŒ€ ë™ì‹œ ìš”ì²­ ìˆ˜
            delay: ìš”ì²­ ê°„ ì§€ì—° ì‹œê°„
        """
        # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œì„± ì œí•œ
        semaphore = asyncio.Semaphore(concurrency)

        async def fetch_with_semaphore(url):
            async with semaphore:
                await self._wait_for_rate_limit()
                try:
                    async with self.session.get(url, params=params) as response:
                        response.raise_for_status()
                        return await response.json()
                except Exception as e:
                    print(f"URL {url} ìš”ì²­ ì‹¤íŒ¨: {e}")
                    return None

        # ëª¨ë“  ìš”ì²­ ì‹¤í–‰
        tasks = [fetch_with_semaphore(url) for url in urls]
        return await asyncio.gather(*tasks)
```

**ë¹„ë™ê¸° ì²˜ë¦¬ì˜ ì¥ì :**

- **I/O ë°”ìš´ë“œ ìµœì í™”**: ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ëŒ€ê¸° ì‹œê°„ ë™ì•ˆ ë‹¤ë¥¸ ì‘ì—… ìˆ˜í–‰
- **ë™ì‹œì„± ì œì–´**: ì„¸ë§ˆí¬ì–´ë¥¼ í†µí•œ ì•ˆì „í•œ ë™ì‹œ ìš”ì²­ ê´€ë¦¬
- **ì†ë„ ì œí•œ ì¤€ìˆ˜**: API ì œí•œì„ ê³ ë ¤í•œ ì§€ëŠ¥ì  ìš”ì²­ ê´€ë¦¬

## 3. ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ

### ë³‘ë ¬ ìŠ¤ì¼€ì¤„ëŸ¬ êµ¬í˜„

**parallel_scheduler.py**

```python
def start_parallel_scheduler():
    """ë³‘ë ¬ ì²˜ë¦¬ ê¸°ëŠ¥ì´ ì¶”ê°€ëœ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
    scheduler = BackgroundScheduler()

    # í†µí•© ë‰´ìŠ¤ í¬ë¡¤ë§ (ê²½ì œ ë‰´ìŠ¤ + ì§€ìˆ˜ ë‰´ìŠ¤)
    scheduler.add_job(
        run_integrated_news_crawling_parallel,
        "interval",
        minutes=90
    )

    # ê°€ê²© ê´€ë ¨ ì‘ì—…
    scheduler.add_job(
        run_high_price_update_job_parallel,
        "interval",
        hours=4
    )

    # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
    scheduler.add_job(
        run_realtime_price_monitor_job_parallel,
        "interval",
        minutes=30
    )

    # ì¼ì¼ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ (ë§¤ì¼ ì˜¤ì „ 8ì‹œ)
    scheduler.add_job(
        run_daily_comprehensive_report,
        "cron",
        hour=8,
        minute=0,
        timezone="Asia/Seoul"
    )

    scheduler.start()
```

**ìŠ¤ì¼€ì¤„ë§ ìµœì í™”:**

- **ì‘ì—… ê°„ê²© ì¡°ì •**: ì‹œìŠ¤í…œ ë¶€í•˜ë¥¼ ê³ ë ¤í•œ ìµœì  ì‹¤í–‰ ì£¼ê¸° ì„¤ì •
- **ì‹œê°„ëŒ€ ê³ ë ¤**: í•œêµ­ ì‹œê°„ ê¸°ì¤€ ìµœì  ì‹¤í–‰ ì‹œê°„ ì„¤ì •
- **ë³‘ë ¬ ì²˜ë¦¬**: ê° ì‘ì—… ë‚´ì—ì„œ ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ í–¥ìƒ

### ì‘ì—…ë³„ ë³‘ë ¬ ì²˜ë¦¬ êµ¬í˜„

**ë‰´ìŠ¤ í¬ë¡¤ë§ ë³‘ë ¬ ì²˜ë¦¬**

```python
@measure_execution_time
def run_integrated_news_crawling_parallel():
    """í†µí•© ë‰´ìŠ¤ í¬ë¡¤ë§ (ê²½ì œ ë‰´ìŠ¤ + ì§€ìˆ˜ ë‰´ìŠ¤)"""

    # 1. Investing ê²½ì œ ë‰´ìŠ¤ í¬ë¡¤ë§
    def process_investing_symbol(symbol):
        crawler = InvestingNewsCrawler(symbol)
        return crawler.process_all()

    investing_results = executor.run_symbol_tasks_parallel(
        process_investing_symbol,
        INVESTING_ECONOMIC_SYMBOLS,
        delay=0.5
    )

    # 2. Yahoo ì§€ìˆ˜ ë‰´ìŠ¤ í¬ë¡¤ë§
    def process_yahoo_symbol(symbol):
        crawler = YahooNewsCrawler(symbol)
        return crawler.process_all()

    yahoo_results = executor.run_symbol_tasks_parallel(
        process_yahoo_symbol,
        INDEX_SYMBOLS,
        delay=0.5
    )

    # ê²°ê³¼ ì§‘ê³„ ë° ë¡œê¹…
    total_success = sum(1 for r in investing_results + yahoo_results if r is not None)
    total_symbols = len(INVESTING_ECONOMIC_SYMBOLS) + len(INDEX_SYMBOLS)
    print(f"ğŸ‰ í†µí•© ë‰´ìŠ¤ í¬ë¡¤ë§ ì™„ë£Œ: {total_success}/{total_symbols} ì„±ê³µ")
```

## 4. ê¸°ìˆ ì  ë¶„ì„ ì—”ì§„

### 20+ ì „ëµ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„

**ì´ë™í‰ê· ì„  ì „ëµ**

```python
async def executeMABreakoutStrategy(candles: List[CandleData], period: int):
    """MA ëŒíŒŒ ì „ëµ êµ¬í˜„"""
    sma = self.indicatorService.calculateSMA(candles, period)
    current_price = candles[-1].close
    current_ma = sma[-1].value

    # 2% ì´ìƒ ëŒíŒŒ ì‹œ ë§¤ìˆ˜ ì‹ í˜¸
    if current_price > current_ma * 1.02:
        return {
            "signal": SignalType.BUY,
            "confidence": 75,
            "reason": f"MA{period} ëŒíŒŒ (í˜„ì¬ê°€: {current_price}, MA: {current_ma})"
        }
```

**RSI ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„ ì „ëµ**

```python
async def executeRSIStrategy(candles: List[CandleData]):
    """RSI ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„ ì „ëµ"""
    rsi = self.indicatorService.calculateRSI(candles, 14)
    current_rsi = rsi[-1].value

    if current_rsi < 30:
        return {
            "signal": SignalType.BUY,
            "confidence": 70,
            "reason": f"RSI ê³¼ë§¤ë„ ë°˜ë“± ì‹ í˜¸ (RSI: {current_rsi})"
        }
    elif current_rsi > 70:
        return {
            "signal": SignalType.SELL,
            "confidence": 70,
            "reason": f"RSI ê³¼ë§¤ìˆ˜ ì¡°ì • ì‹ í˜¸ (RSI: {current_rsi})"
        }
```

**ë³µí•© ì „ëµ (íŠ¸ë¦¬í”Œ í™•ì¸)**

```python
async def executeTripleConfirmationStrategy(candles: List[CandleData]):
    """íŠ¸ë¦¬í”Œ í™•ì¸ ì „ëµ (MA + RSI + Volume)"""
    ma_signal = await self.executeMAStrategy(candles)
    rsi_signal = await self.executeRSIStrategy(candles)
    volume_signal = await self.executeVolumeStrategy(candles)

    # 3ê°œ ì§€í‘œ ëª¨ë‘ ë™ì¼í•œ ì‹ í˜¸ì¼ ë•Œë§Œ ì‹¤í–‰
    if (ma_signal.signal == rsi_signal.signal == volume_signal.signal):
        return {
            "signal": ma_signal.signal,
            "confidence": 85,  # ë†’ì€ ì‹ ë¢°ë„
            "reason": "íŠ¸ë¦¬í”Œ í™•ì¸ (MA + RSI + Volume ì¼ì¹˜)"
        }
```

### ë°±í…ŒìŠ¤íŒ… ì‹œìŠ¤í…œ

**ê³¼ê±° ë°ì´í„° ê¸°ë°˜ ì „ëµ ê²€ì¦**

```python
class BacktestingService:
    """ë°±í…ŒìŠ¤íŒ… ì„œë¹„ìŠ¤"""

    def analyze_all_signals_performance(
        self,
        timeframe_eval: str = "1d",
        min_samples: int = 10
    ):
        """ì „ì²´ ì‹ í˜¸ ì„±ê³¼ ë¶„ì„"""

        # 1. ëª¨ë“  ì‹ í˜¸ ì¡°íšŒ
        signals = self.get_all_historical_signals()

        # 2. ì „ëµë³„ ì„±ê³¼ ê³„ì‚°
        strategy_performance = {}
        for signal in signals:
            strategy = signal.signal_type
            if strategy not in strategy_performance:
                strategy_performance[strategy] = {
                    "total_signals": 0,
                    "successful_signals": 0,
                    "total_return": 0,
                    "returns": []
                }

            # ì„±ê³¼ ê³„ì‚°
            outcome = self.calculate_signal_outcome(signal, timeframe_eval)
            strategy_performance[strategy]["total_signals"] += 1

            if outcome["return"] > 0:
                strategy_performance[strategy]["successful_signals"] += 1

            strategy_performance[strategy]["total_return"] += outcome["return"]
            strategy_performance[strategy]["returns"].append(outcome["return"])

        # 3. í†µê³„ ê³„ì‚°
        results = {}
        for strategy, perf in strategy_performance.items():
            if perf["total_signals"] >= min_samples:
                success_rate = perf["successful_signals"] / perf["total_signals"]
                avg_return = perf["total_return"] / perf["total_signals"]

                results[strategy] = {
                    "success_rate": success_rate,
                    "avg_return": avg_return,
                    "total_signals": perf["total_signals"],
                    "sharpe_ratio": self.calculate_sharpe_ratio(perf["returns"])
                }

        return results
```

## 5. ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”

### ì—°ê²° í’€ë§ ì„¤ì •

**database_config.py**

```python
# SQLAlchemy ì—”ì§„ ìƒì„± - ì—°ê²° í’€ë§ ìµœì í™”
engine = create_engine(
    MYSQL_URL,
    echo=False,  # SQL ì¿¼ë¦¬ ë¡œê¹… ë¹„í™œì„±í™” (ì„±ëŠ¥ í–¥ìƒ)

    # ì—°ê²° í’€ë§ ì„¤ì • (ì„±ëŠ¥ ê°œì„ ì˜ í•µì‹¬)
    pool_size=20,           # ê¸°ë³¸ ì—°ê²° í’€ í¬ê¸°
    max_overflow=30,        # ì¶”ê°€ ì—°ê²° í—ˆìš© ìˆ˜
    pool_timeout=300,       # ì—°ê²° ëŒ€ê¸° ì‹œê°„ (5ë¶„)
    pool_recycle=600,       # ì—°ê²° ì¬ì‚¬ìš© ì‹œê°„ (10ë¶„)
    pool_pre_ping=True,     # ì—°ê²° ìœ íš¨ì„± ê²€ì‚¬

    # ì¶”ê°€ ìµœì í™” ì„¤ì •
    connect_args={
        "charset": "utf8mb4",
        "autocommit": False,
        "connect_timeout": 60,
        "read_timeout": 60,
        "write_timeout": 60,
    },
)
```

### ì„¸ì…˜ ê´€ë¦¬ ìµœì í™”

**db_session_manager.py**

```python
@contextmanager
def session_scope() -> Generator[Session, None, None]:
    """
    ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € - íŠ¸ëœì­ì…˜ ìë™ ê´€ë¦¬

    ì‚¬ìš© ì˜ˆ:
    with session_scope() as session:
        # ì„¸ì…˜ ì‚¬ìš©
        session.query(...)
    # ìë™ìœ¼ë¡œ ì»¤ë°‹ ë˜ëŠ” ë¡¤ë°± í›„ ì„¸ì…˜ ë‹«í˜
    """
    session = SessionLocal()
    try:
        yield session
        session.commit()
    except SQLAlchemyError as e:
        session.rollback()
        logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜: {e}")
        raise
    except Exception as e:
        session.rollback()
        logger.error(f"ì¼ë°˜ ì˜¤ë¥˜: {e}")
        raise
    finally:
        session.close()
```

**ì„¸ì…˜ ê´€ë¦¬ì˜ ì¥ì :**

- **ìë™ íŠ¸ëœì­ì…˜ ê´€ë¦¬**: ì»¤ë°‹/ë¡¤ë°± ìë™ ì²˜ë¦¬
- **ë¦¬ì†ŒìŠ¤ ì •ë¦¬**: ì„¸ì…˜ ìë™ ì¢…ë£Œë¡œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€
- **ì—ëŸ¬ ì²˜ë¦¬**: ì˜ˆì™¸ ë°œìƒ ì‹œ ì•ˆì „í•œ ë¡¤ë°±

## 6. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

### ì‹¤í–‰ ì‹œê°„ ì¸¡ì •

**performance_monitor.py**

```python
class PerformanceMetrics:
    """ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘ ë° ê´€ë¦¬"""

    def record_execution_time(self, name: str, duration: float):
        """ì‹¤í–‰ ì‹œê°„ ê¸°ë¡"""
        with self.lock:
            if name not in self.metrics:
                self.metrics[name] = {
                    "count": 0,
                    "total_time": 0,
                    "min_time": float("inf"),
                    "max_time": 0,
                    "avg_time": 0,
                    "last_time": 0,
                    "timestamps": [],
                }

            metrics = self.metrics[name]
            metrics["count"] += 1
            metrics["total_time"] += duration
            metrics["min_time"] = min(metrics["min_time"], duration)
            metrics["max_time"] = max(metrics["max_time"], duration)
            metrics["avg_time"] = metrics["total_time"] / metrics["count"]
            metrics["last_time"] = duration

@measure_execution_time
def run_integrated_news_crawling_parallel():
    """ì‹¤í–‰ ì‹œê°„ì´ ìë™ìœ¼ë¡œ ì¸¡ì •ë˜ëŠ” í•¨ìˆ˜"""
    # í•¨ìˆ˜ ì‹¤í–‰ ë‚´ìš©
    pass
```

### ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§

```python
class ResourceMonitor:
    """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§"""

    def _monitor_resources(self):
        """ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ"""
        while self.running:
            try:
                # CPU ì‚¬ìš©ë¥ 
                cpu_percent = psutil.cpu_percent(interval=1)

                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
                memory = psutil.Process().memory_info()
                memory_mb = memory.rss / (1024 * 1024)

                # ì§€í‘œ ê¸°ë¡
                performance_metrics.record_resource_usage(
                    "system", cpu_percent, memory_mb
                )

                time.sleep(self.interval)
            except Exception as e:
                logger.error(f"ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
```

## 7. í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì‹œìŠ¤í…œ

### ì¼ì¼ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±

**daily_comprehensive_report_service.py**

```python
class DailyComprehensiveReportService:
    """ì¼ì¼ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ì„œë¹„ìŠ¤"""

    def generate_daily_report(self):
        """ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„± ë° ì „ì†¡"""

        # 1. ë°±í…ŒìŠ¤íŒ… ì„±ê³¼ ë¶„ì„
        backtesting_results = self.analyze_backtesting_performance()

        # 2. íŒ¨í„´ ë¶„ì„ ê²°ê³¼
        pattern_results = self.analyze_patterns()

        # 3. ë¨¸ì‹ ëŸ¬ë‹ ë¶„ì„
        ml_results = self.analyze_ml_clusters()

        # 4. íˆ¬ì ì¸ì‚¬ì´íŠ¸ ìƒì„±
        insights = self.generate_investment_insights()

        # 5. ë¦¬í¬íŠ¸ í¬ë§·íŒ…
        report = self.format_daily_report({
            "backtesting": backtesting_results,
            "patterns": pattern_results,
            "ml_analysis": ml_results,
            "insights": insights
        })

        # 6. í…”ë ˆê·¸ë¨ ì „ì†¡
        return self.send_telegram_report(report)

    def format_daily_report(self, data):
        """ë¦¬í¬íŠ¸ í¬ë§·íŒ…"""
        report = f"""ğŸŒ… ì¼ì¼ í€€íŠ¸ ë¶„ì„ ë¦¬í¬íŠ¸ ({datetime.now().strftime('%Y.%m.%d %H:%M')})

ğŸ“ˆ ë°±í…ŒìŠ¤íŒ… ì„±ê³¼ ë¶„ì„
â”Œâ”€ ë‚˜ìŠ¤ë‹¥ ì§€ìˆ˜ (^IXIC)
â”‚  â€¢ ìµœê³  ì„±ê³¼ ì „ëµ: {data['backtesting']['nasdaq']['best_strategy']}
â”‚  â€¢ í‰ê·  ìˆ˜ìµë¥ : {data['backtesting']['nasdaq']['avg_return']:.1f}% (1ì¼ ê¸°ì¤€)
â”‚  â€¢ ìŠ¹ë¥ : {data['backtesting']['nasdaq']['success_rate']:.1f}%
â”‚  â€¢ ì „ì²´ ì‹ í˜¸ ì •í™•ë„: {data['backtesting']['nasdaq']['accuracy']:.1f}%

ğŸ¯ ì˜¤ëŠ˜ì˜ íˆ¬ì ì¸ì‚¬ì´íŠ¸
{self.format_insights(data['insights'])}

ğŸ“š ìš©ì–´ í•´ì„¤
ğŸ”¹ ë°±í…ŒìŠ¤íŒ…: ê³¼ê±° ë°ì´í„°ë¡œ ì „ëµì„ í…ŒìŠ¤íŠ¸í•´ì„œ "ë§Œì•½ ì´ë ‡ê²Œ íˆ¬ìí–ˆë‹¤ë©´?"ì„ ê³„ì‚°
ğŸ”¹ ê³¨ë“ í¬ë¡œìŠ¤: ë‹¨ê¸°ì„ ì´ ì¥ê¸°ì„ ì„ ìœ„ë¡œ ëš«ê³  ì˜¬ë¼ê°€ëŠ” ê°•í•œ ìƒìŠ¹ ì‹ í˜¸ ğŸš€
"""
        return report
```

### ì‹¤ì‹œê°„ ì‹ í˜¸ ì•Œë¦¼

```python
class TechnicalMonitorService:
    """ê¸°ìˆ ì  ì§€í‘œ ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤"""

    def send_signal_notification(self, signal):
        """ì‹ í˜¸ ì•Œë¦¼ ì „ì†¡"""

        # ì‹ í˜¸ ê°•ë„ë³„ ìš°ì„ ìˆœìœ„ ê²°ì •
        priority = self.determine_priority(signal)

        if priority == NotificationPriority.HIGH:
            # ì¦‰ì‹œ ì•Œë¦¼
            message = f"""ğŸš¨ ì¤‘ìš” ì‹ í˜¸ ë°œìƒ!

ğŸ“Š {signal.symbol} - {signal.signal_type}
ğŸ’° í˜„ì¬ê°€: ${signal.current_price:.2f}
ğŸ“ˆ ì‹ ë¢°ë„: {signal.confidence}%
ğŸ¯ ì˜ˆìƒ ë°©í–¥: {signal.direction}

ğŸ“ ë¶„ì„ ë‚´ìš©:
{signal.analysis_detail}

â° ë°œìƒ ì‹œê°„: {signal.timestamp}
"""
            self.telegram_service.send_message(message)

        elif priority == NotificationPriority.MEDIUM:
            # ì¼ë°˜ ì•Œë¦¼ (ë°°ì¹˜ë¡œ ì²˜ë¦¬)
            self.add_to_batch_notification(signal)
```

## 8. í…ŒìŠ¤íŠ¸ ë° í’ˆì§ˆ ê´€ë¦¬

### í†µí•© í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ

**test_router.py**

```python
@router.post('/analysis-flow')
async def test_analysis_flow(request: dict):
    """ì „ì²´ í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    start_time = time.time()

    try:
        # 1. ìº”ë“¤ ë°ì´í„° ì¡°íšŒ
        candles = await candle_service.get_latest_candles(request['symbol'])

        # 2. ê¸°ìˆ ì  ë¶„ì„ ì‹¤í–‰
        analysis_result = await technical_analysis_service.analyze_symbol(
            request['symbol'],
            [StrategyType.RSI_OVERSOLD_BOUNCE, StrategyType.MA_20_BREAKOUT]
        )

        # 3. ì•Œë¦¼ í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ë°œì†¡ ì•ˆ í•¨)
        notification = await notification_service.prepare_notification(analysis_result)

        return {
            "success": True,
            "execution_time": time.time() - start_time,
            "result": {
                "candles_count": len(candles),
                "signals_count": len(analysis_result.signals),
                "notification_prepared": bool(notification)
            }
        }
    except Exception as e:
        return {"success": False, "error": str(e)}
```

### í—¬ìŠ¤ì²´í¬ ì‹œìŠ¤í…œ

```python
@router.get('/health')
async def get_health_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "database": await check_database_connection(),
            "telegram_bot": await telegram_service.check_connection(),
            "scheduler": scheduler.get_status()
        },
        "features": [
            "ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘",
            "20+ ê¸°ìˆ ì  ë¶„ì„ ì „ëµ",
            "ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ",
            "í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì‹œìŠ¤í…œ",
            "ë°±í…ŒìŠ¤íŒ… ì—”ì§„",
            "ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"
        ],
        "performance": performance_metrics.get_summary()
    }
```

## 9. í˜„ì¬ ìš´ì˜ í˜„í™© ë° í–¥í›„ ê°œì„  ê³„íš

### í˜„ì¬ ìƒí™©

- **ì‚¬ìš©ì ê·œëª¨**: ê°œë°œì ë³¸ì¸ + ì†Œìˆ˜ í…ŒìŠ¤í„°
- **ë°ì´í„° ê·œëª¨**: 10ë…„ì¹˜ íˆìŠ¤í† ë¦¬ì»¬ ë°ì´í„° (140,000ê°œ ìº”ë“¤)
- **ì²˜ë¦¬ ì„±ëŠ¥**: 1.5ì´ˆ ì´ë‚´ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ
- **ì‹œìŠ¤í…œ ì•ˆì •ì„±**: 24ì‹œê°„ ê°€ë™ë¥  99% ì´ìƒ

### í˜„ì¬ í•œê³„ì 

- **í™•ì¥ì„±**: ì‚¬ìš©ì ì¦ê°€ ì‹œ ëŒ€ì‘ ë°©ì•ˆ ë¯¸ê²€ì¦
- **ëª¨ë‹ˆí„°ë§**: ê¸°ë³¸ì ì¸ ì„±ëŠ¥ ë¡œê¹… ìˆ˜ì¤€
- **ì¥ì•  ë³µêµ¬**: ì‹¤ì œ ëŒ€ê·œëª¨ ì¥ì•  ìƒí™© ê²½í—˜ ë¶€ì¡±

### í–¥í›„ ê°œì„  ê³„íš

**ì„±ëŠ¥ ìµœì í™”**

- ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìµœì í™” ë° ì¸ë±ìŠ¤ íŠœë‹
- ìºì‹± ì „ëµ ê³ ë„í™” (Redis ë„ì…)
- ì—°ê²° í’€ íŠœë‹ ë° ë¶€í•˜ ë¶„ì‚°

**ëª¨ë‹ˆí„°ë§ ê°•í™”**

- ìƒì„¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (Prometheus + Grafana)
- ì‹¤ì‹œê°„ ì•Œë¦¼ ì‹œìŠ¤í…œ ê³ ë„í™”
- ë¡œê·¸ ë¶„ì„ ì‹œìŠ¤í…œ êµ¬ì¶• (ELK Stack)

**í™•ì¥ì„± ê°œì„ **

- ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ë¡œ ë¶„ë¦¬
- ì»¨í…Œì´ë„ˆ ê¸°ë°˜ ë°°í¬ (Docker + Kubernetes)
- ë°ì´í„°ë² ì´ìŠ¤ ìƒ¤ë”© ë° ì½ê¸° ì „ìš© ë³µì œë³¸

**ìš´ì˜ ì•ˆì •ì„±**

- ìë™ ì¥ì•  ë³µêµ¬ ì‹œìŠ¤í…œ
- ë°±ì—…/ë³µêµ¬ ìë™í™”
- ë³´ì•ˆ ê°•í™” (API í‚¤ ê´€ë¦¬, ì ‘ê·¼ ì œì–´)

---

**Finstage Market Data ë°±ì—”ë“œëŠ” í™•ì¥ ê°€ëŠ¥í•˜ê³  ì•ˆì •ì ì¸ ì‹¤ì‹œê°„ ê¸ˆìœµ ë°ì´í„° ë¶„ì„ í”Œë«í¼ì„ êµ¬í˜„í•˜ê¸° ìœ„í•œ í˜„ëŒ€ì ì¸ ì•„í‚¤í…ì²˜ì™€ ê¸°ìˆ  ìŠ¤íƒì„ í™œìš©í•©ë‹ˆë‹¤.**
