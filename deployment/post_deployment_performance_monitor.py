#!/usr/bin/env python3
"""
ë°°í¬ í›„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° íŠœë‹ ì‹œìŠ¤í…œ

ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œ ì„±ëŠ¥ ì§€í‘œë¥¼ ìˆ˜ì§‘í•˜ê³  ìë™ íŠœë‹ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""

import asyncio
import time
import psutil
import statistics
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
import json
import sys
import os
from dataclasses import dataclass, asdict
from enum import Enum

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.common.monitoring.performance_metrics_collector import get_metrics_collector
from app.common.optimization.optimization_manager import get_optimization_manager
from app.common.monitoring.alert_system import get_alert_system
from app.common.utils.memory_cache import get_cache
from app.common.utils.logging_config import get_logger

logger = get_logger(__name__)


class PerformanceStatus(Enum):
    """ì„±ëŠ¥ ìƒíƒœ"""

    EXCELLENT = "excellent"
    GOOD = "good"
    FAIR = "fair"
    POOR = "poor"
    CRITICAL = "critical"


@dataclass
class PerformanceThreshold:
    """ì„±ëŠ¥ ì„ê³„ê°’"""

    memory_usage_percent: float = 80.0  # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì„ê³„ê°’
    cpu_usage_percent: float = 70.0  # CPU ì‚¬ìš©ë¥  ì„ê³„ê°’
    response_time_ms: float = 1000.0  # ì‘ë‹µ ì‹œê°„ ì„ê³„ê°’
    error_rate_percent: float = 5.0  # ì—ëŸ¬ìœ¨ ì„ê³„ê°’
    cache_hit_rate_percent: float = 80.0  # ìºì‹œ íˆíŠ¸ìœ¨ ì„ê³„ê°’


@dataclass
class PerformanceMetrics:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­"""

    timestamp: datetime
    memory_usage_percent: float
    cpu_usage_percent: float
    avg_response_time_ms: float
    p95_response_time_ms: float
    error_rate_percent: float
    cache_hit_rate_percent: float
    active_connections: int
    requests_per_second: float
    status: PerformanceStatus


class PostDeploymentMonitor:
    """ë°°í¬ í›„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ"""

    def __init__(self, monitoring_interval: int = 60):
        self.monitoring_interval = monitoring_interval  # ëª¨ë‹ˆí„°ë§ ê°„ê²© (ì´ˆ)
        self.metrics_collector = get_metrics_collector()
        self.optimization_manager = get_optimization_manager()
        self.alert_system = get_alert_system()

        # ì„±ëŠ¥ ì„ê³„ê°’
        self.thresholds = PerformanceThreshold()

        # ì„±ëŠ¥ íˆìŠ¤í† ë¦¬
        self.performance_history: List[PerformanceMetrics] = []
        self.max_history_size = 1440  # 24ì‹œê°„ (1ë¶„ ê°„ê²©)

        # ìë™ íŠœë‹ ì„¤ì •
        self.auto_tuning_enabled = True
        self.last_tuning_time = None
        self.tuning_cooldown = timedelta(minutes=30)  # íŠœë‹ ê°„ ìµœì†Œ ê°„ê²©

        # ì„±ëŠ¥ ì €í•˜ ê°ì§€
        self.performance_degradation_threshold = 20.0  # 20% ì„±ëŠ¥ ì €í•˜ ì‹œ ì•Œë¦¼
        self.consecutive_poor_performance_limit = 5  # ì—°ì† 5íšŒ ì„±ëŠ¥ ì €í•˜ ì‹œ ì¡°ì¹˜

        self.is_monitoring = False

    async def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self.is_monitoring:
            logger.warning("monitoring_already_running")
            return

        self.is_monitoring = True
        logger.info(
            "post_deployment_monitoring_started", interval=self.monitoring_interval
        )

        print("ğŸš€ ë°°í¬ í›„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        print(f"   ğŸ“Š ëª¨ë‹ˆí„°ë§ ê°„ê²©: {self.monitoring_interval}ì´ˆ")
        print(
            f"   ğŸ¯ ìë™ íŠœë‹: {'í™œì„±í™”' if self.auto_tuning_enabled else 'ë¹„í™œì„±í™”'}"
        )
        print("=" * 50)

        try:
            while self.is_monitoring:
                await self._collect_and_analyze_metrics()
                await asyncio.sleep(self.monitoring_interval)

        except Exception as e:
            logger.error("monitoring_error", error=str(e))
            print(f"âŒ ëª¨ë‹ˆí„°ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        finally:
            self.is_monitoring = False

    def stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.is_monitoring = False
        logger.info("post_deployment_monitoring_stopped")
        print("â¹ï¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")

    async def _collect_and_analyze_metrics(self):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ë¶„ì„"""
        try:
            # í˜„ì¬ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            metrics = await self._collect_current_metrics()

            # ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.performance_history.append(metrics)
            if len(self.performance_history) > self.max_history_size:
                self.performance_history.pop(0)

            # ì„±ëŠ¥ ë¶„ì„
            await self._analyze_performance(metrics)

            # ì„±ëŠ¥ ìƒíƒœ ì¶œë ¥
            self._print_performance_status(metrics)

            # ìë™ íŠœë‹ ê²€í† 
            if self.auto_tuning_enabled:
                await self._check_auto_tuning(metrics)

        except Exception as e:
            logger.error("metrics_collection_failed", error=str(e))

    async def _collect_current_metrics(self) -> PerformanceMetrics:
        """í˜„ì¬ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        try:
            # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
            memory_info = psutil.virtual_memory()
            cpu_percent = psutil.cpu_percent(interval=1)

            # ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­ (ë©”íŠ¸ë¦­ ì»¬ë ‰í„°ì—ì„œ ìˆ˜ì§‘)
            app_metrics = self.metrics_collector.get_current_metrics()

            # ìºì‹œ ì„±ëŠ¥ ë©”íŠ¸ë¦­
            cache_metrics = await self._get_cache_metrics()

            # ì„±ëŠ¥ ìƒíƒœ íŒë‹¨
            status = self._determine_performance_status(
                memory_info.percent,
                cpu_percent,
                app_metrics.get("avg_response_time", 0),
                app_metrics.get("error_rate", 0),
                cache_metrics.get("hit_rate", 0),
            )

            return PerformanceMetrics(
                timestamp=datetime.now(),
                memory_usage_percent=memory_info.percent,
                cpu_usage_percent=cpu_percent,
                avg_response_time_ms=app_metrics.get("avg_response_time", 0),
                p95_response_time_ms=app_metrics.get("p95_response_time", 0),
                error_rate_percent=app_metrics.get("error_rate", 0),
                cache_hit_rate_percent=cache_metrics.get("hit_rate", 0),
                active_connections=app_metrics.get("active_connections", 0),
                requests_per_second=app_metrics.get("requests_per_second", 0),
                status=status,
            )

        except Exception as e:
            logger.error("current_metrics_collection_failed", error=str(e))
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ë©”íŠ¸ë¦­ ë°˜í™˜
            return PerformanceMetrics(
                timestamp=datetime.now(),
                memory_usage_percent=0,
                cpu_usage_percent=0,
                avg_response_time_ms=0,
                p95_response_time_ms=0,
                error_rate_percent=0,
                cache_hit_rate_percent=0,
                active_connections=0,
                requests_per_second=0,
                status=PerformanceStatus.FAIR,
            )

    async def _get_cache_metrics(self) -> Dict[str, float]:
        """ìºì‹œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        try:
            cache_names = ["technical_analysis", "price_data", "news_data"]
            total_hits = 0
            total_requests = 0

            for cache_name in cache_names:
                try:
                    cache = get_cache(cache_name)
                    if hasattr(cache, "get_stats"):
                        stats = cache.get_stats()
                        total_hits += stats.get("hits", 0)
                        total_requests += stats.get("requests", 0)
                except Exception:
                    continue

            hit_rate = (total_hits / total_requests * 100) if total_requests > 0 else 0

            return {
                "hit_rate": hit_rate,
                "total_hits": total_hits,
                "total_requests": total_requests,
            }

        except Exception as e:
            logger.error("cache_metrics_collection_failed", error=str(e))
            return {"hit_rate": 0, "total_hits": 0, "total_requests": 0}

    def _determine_performance_status(
        self,
        memory_percent: float,
        cpu_percent: float,
        response_time: float,
        error_rate: float,
        cache_hit_rate: float,
    ) -> PerformanceStatus:
        """ì„±ëŠ¥ ìƒíƒœ íŒë‹¨"""
        # ì„ê³„ ìƒí™© ì²´í¬
        if (
            memory_percent > 95
            or cpu_percent > 90
            or response_time > 5000
            or error_rate > 20
        ):
            return PerformanceStatus.CRITICAL

        # ë‚˜ìœ ì„±ëŠ¥ ì²´í¬
        if (
            memory_percent > self.thresholds.memory_usage_percent
            or cpu_percent > self.thresholds.cpu_usage_percent
            or response_time > self.thresholds.response_time_ms
            or error_rate > self.thresholds.error_rate_percent
        ):
            return PerformanceStatus.POOR

        # ë³´í†µ ì„±ëŠ¥ ì²´í¬
        if (
            memory_percent > 60
            or cpu_percent > 50
            or response_time > 500
            or cache_hit_rate < 70
        ):
            return PerformanceStatus.FAIR

        # ì¢‹ì€ ì„±ëŠ¥ ì²´í¬
        if (
            memory_percent < 40
            and cpu_percent < 30
            and response_time < 200
            and cache_hit_rate > 90
        ):
            return PerformanceStatus.EXCELLENT

        return PerformanceStatus.GOOD

    async def _analyze_performance(self, current_metrics: PerformanceMetrics):
        """ì„±ëŠ¥ ë¶„ì„ ë° ì•Œë¦¼"""
        try:
            # ì„±ëŠ¥ ì €í•˜ ê°ì§€
            if len(self.performance_history) >= 2:
                await self._detect_performance_degradation(current_metrics)

            # ì„ê³„ê°’ ì´ˆê³¼ ì•Œë¦¼
            await self._check_threshold_violations(current_metrics)

            # ì—°ì† ì„±ëŠ¥ ì €í•˜ ê°ì§€
            await self._check_consecutive_poor_performance()

        except Exception as e:
            logger.error("performance_analysis_failed", error=str(e))

    async def _detect_performance_degradation(
        self, current_metrics: PerformanceMetrics
    ):
        """ì„±ëŠ¥ ì €í•˜ ê°ì§€"""
        try:
            # ìµœê·¼ 10ë¶„ê°„ì˜ í‰ê· ê³¼ ë¹„êµ
            recent_history = [
                m
                for m in self.performance_history[-10:]
                if m.timestamp > datetime.now() - timedelta(minutes=10)
            ]

            if len(recent_history) < 5:
                return

            # í‰ê·  ì‘ë‹µ ì‹œê°„ ë¹„êµ
            avg_response_time = statistics.mean(
                [m.avg_response_time_ms for m in recent_history]
            )
            current_response_time = current_metrics.avg_response_time_ms

            if avg_response_time > 0:
                degradation_percent = (
                    (current_response_time - avg_response_time) / avg_response_time
                ) * 100

                if degradation_percent > self.performance_degradation_threshold:
                    await self.alert_system.send_alert(
                        "performance_degradation",
                        f"ì‘ë‹µ ì‹œê°„ì´ {degradation_percent:.1f}% ì €í•˜ë˜ì—ˆìŠµë‹ˆë‹¤. "
                        f"í˜„ì¬: {current_response_time:.1f}ms, í‰ê· : {avg_response_time:.1f}ms",
                        severity="warning",
                    )

                    logger.warning(
                        "performance_degradation_detected",
                        degradation_percent=degradation_percent,
                        current_response_time=current_response_time,
                        avg_response_time=avg_response_time,
                    )

        except Exception as e:
            logger.error("performance_degradation_detection_failed", error=str(e))

    async def _check_threshold_violations(self, metrics: PerformanceMetrics):
        """ì„ê³„ê°’ ìœ„ë°˜ ì²´í¬"""
        violations = []

        if metrics.memory_usage_percent > self.thresholds.memory_usage_percent:
            violations.append(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {metrics.memory_usage_percent:.1f}%")

        if metrics.cpu_usage_percent > self.thresholds.cpu_usage_percent:
            violations.append(f"CPU ì‚¬ìš©ë¥ : {metrics.cpu_usage_percent:.1f}%")

        if metrics.avg_response_time_ms > self.thresholds.response_time_ms:
            violations.append(f"ì‘ë‹µ ì‹œê°„: {metrics.avg_response_time_ms:.1f}ms")

        if metrics.error_rate_percent > self.thresholds.error_rate_percent:
            violations.append(f"ì—ëŸ¬ìœ¨: {metrics.error_rate_percent:.1f}%")

        if metrics.cache_hit_rate_percent < self.thresholds.cache_hit_rate_percent:
            violations.append(f"ìºì‹œ íˆíŠ¸ìœ¨: {metrics.cache_hit_rate_percent:.1f}%")

        if violations:
            severity = (
                "critical"
                if metrics.status == PerformanceStatus.CRITICAL
                else "warning"
            )
            await self.alert_system.send_alert(
                "threshold_violation",
                f"ì„±ëŠ¥ ì„ê³„ê°’ ìœ„ë°˜: {', '.join(violations)}",
                severity=severity,
            )

    async def _check_consecutive_poor_performance(self):
        """ì—°ì† ì„±ëŠ¥ ì €í•˜ ì²´í¬"""
        if len(self.performance_history) < self.consecutive_poor_performance_limit:
            return

        recent_metrics = self.performance_history[
            -self.consecutive_poor_performance_limit :
        ]
        poor_performance_count = sum(
            1
            for m in recent_metrics
            if m.status in [PerformanceStatus.POOR, PerformanceStatus.CRITICAL]
        )

        if poor_performance_count >= self.consecutive_poor_performance_limit:
            await self.alert_system.send_alert(
                "consecutive_poor_performance",
                f"ì—°ì† {poor_performance_count}íšŒ ì„±ëŠ¥ ì €í•˜ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ìë™ íŠœë‹ì„ ê²€í† í•©ë‹ˆë‹¤.",
                severity="critical",
            )

            # ê°•ì œ ìë™ íŠœë‹ ì‹¤í–‰
            if self.auto_tuning_enabled:
                await self._force_auto_tuning("consecutive_poor_performance")

    async def _check_auto_tuning(self, metrics: PerformanceMetrics):
        """ìë™ íŠœë‹ ê²€í† """
        try:
            # ì¿¨ë‹¤ìš´ ì‹œê°„ ì²´í¬
            if (
                self.last_tuning_time
                and datetime.now() - self.last_tuning_time < self.tuning_cooldown
            ):
                return

            # íŠœë‹ì´ í•„ìš”í•œ ìƒí™© ì²´í¬
            tuning_needed = False
            tuning_reason = []

            # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ì€ ê²½ìš°
            if metrics.memory_usage_percent > 85:
                tuning_needed = True
                tuning_reason.append("high_memory_usage")

            # ì‘ë‹µ ì‹œê°„ì´ ê¸´ ê²½ìš°
            if metrics.avg_response_time_ms > 1500:
                tuning_needed = True
                tuning_reason.append("slow_response_time")

            # ìºì‹œ íˆíŠ¸ìœ¨ì´ ë‚®ì€ ê²½ìš°
            if metrics.cache_hit_rate_percent < 60:
                tuning_needed = True
                tuning_reason.append("low_cache_hit_rate")

            if tuning_needed:
                await self._perform_auto_tuning(tuning_reason, metrics)

        except Exception as e:
            logger.error("auto_tuning_check_failed", error=str(e))

    async def _perform_auto_tuning(
        self, reasons: List[str], metrics: PerformanceMetrics
    ):
        """ìë™ íŠœë‹ ìˆ˜í–‰"""
        try:
            self.last_tuning_time = datetime.now()

            logger.info("auto_tuning_started", reasons=reasons)
            print(f"ğŸ”§ ìë™ íŠœë‹ ì‹œì‘: {', '.join(reasons)}")

            tuning_actions = []

            # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ì€ ê²½ìš°
            if "high_memory_usage" in reasons:
                # ë©”ëª¨ë¦¬ ìµœì í™” í™œì„±í™”
                result = self.optimization_manager.enable_optimization(
                    "memory_optimization_aggressive"
                )
                if result.status.value == "enabled":
                    tuning_actions.append("ë©”ëª¨ë¦¬ ìµœì í™” ê°•í™”")

                # ìºì‹œ í¬ê¸° ì¡°ì •
                await self._adjust_cache_sizes(reduce=True)
                tuning_actions.append("ìºì‹œ í¬ê¸° ì¶•ì†Œ")

            # ì‘ë‹µ ì‹œê°„ì´ ê¸´ ê²½ìš°
            if "slow_response_time" in reasons:
                # ë¹„ë™ê¸° ì²˜ë¦¬ ìµœì í™” í™œì„±í™”
                result = self.optimization_manager.enable_optimization(
                    "async_api_endpoints"
                )
                if result.status.value == "enabled":
                    tuning_actions.append("ë¹„ë™ê¸° ì²˜ë¦¬ ìµœì í™”")

                # ì‘ì—… í ìš°ì„ ìˆœìœ„ ì¡°ì •
                await self._adjust_task_queue_priorities()
                tuning_actions.append("ì‘ì—… í ìš°ì„ ìˆœìœ„ ì¡°ì •")

            # ìºì‹œ íˆíŠ¸ìœ¨ì´ ë‚®ì€ ê²½ìš°
            if "low_cache_hit_rate" in reasons:
                # ìºì‹œ TTL ì¡°ì •
                await self._adjust_cache_ttl(increase=True)
                tuning_actions.append("ìºì‹œ TTL ì¦ê°€")

                # ìºì‹œ ì›Œë°ì—… ì‹¤í–‰
                await self._perform_cache_warmup()
                tuning_actions.append("ìºì‹œ ì›Œë°ì—… ì‹¤í–‰")

            # íŠœë‹ ê²°ê³¼ ì•Œë¦¼
            await self.alert_system.send_alert(
                "auto_tuning_completed",
                f"ìë™ íŠœë‹ ì™„ë£Œ: {', '.join(tuning_actions)}",
                severity="info",
            )

            print(f"   âœ… ìë™ íŠœë‹ ì™„ë£Œ: {', '.join(tuning_actions)}")

        except Exception as e:
            logger.error("auto_tuning_failed", error=str(e))
            print(f"   âŒ ìë™ íŠœë‹ ì‹¤íŒ¨: {str(e)}")

    async def _force_auto_tuning(self, reason: str):
        """ê°•ì œ ìë™ íŠœë‹ ì‹¤í–‰"""
        try:
            logger.info("force_auto_tuning_started", reason=reason)
            print(f"ğŸš¨ ê°•ì œ ìë™ íŠœë‹ ì‹œì‘: {reason}")

            # ëª¨ë“  ìµœì í™” í™œì„±í™”
            optimizations = [
                "memory_optimization_aggressive",
                "caching_technical_analysis",
                "caching_price_data",
                "async_api_endpoints",
            ]

            enabled_count = 0
            for opt_id in optimizations:
                try:
                    result = self.optimization_manager.enable_optimization(opt_id)
                    if result.status.value == "enabled":
                        enabled_count += 1
                except Exception:
                    continue

            # ìºì‹œ ì •ë¦¬ ë° ì¬êµ¬ì„±
            await self._emergency_cache_cleanup()

            # ë©”ëª¨ë¦¬ ê°•ì œ ì •ë¦¬
            await self._emergency_memory_cleanup()

            print(f"   âœ… ê°•ì œ íŠœë‹ ì™„ë£Œ: {enabled_count}ê°œ ìµœì í™” í™œì„±í™”")

            await self.alert_system.send_alert(
                "force_auto_tuning_completed",
                f"ê°•ì œ ìë™ íŠœë‹ ì™„ë£Œ: {enabled_count}ê°œ ìµœì í™” í™œì„±í™”",
                severity="warning",
            )

        except Exception as e:
            logger.error("force_auto_tuning_failed", error=str(e))

    async def _adjust_cache_sizes(self, reduce: bool = True):
        """ìºì‹œ í¬ê¸° ì¡°ì •"""
        try:
            cache_names = ["technical_analysis", "price_data", "news_data"]

            for cache_name in cache_names:
                try:
                    cache = get_cache(cache_name)
                    if hasattr(cache, "adjust_max_size"):
                        current_size = getattr(cache, "max_size", 1000)
                        if reduce:
                            new_size = max(100, int(current_size * 0.7))  # 30% ê°ì†Œ
                        else:
                            new_size = int(current_size * 1.3)  # 30% ì¦ê°€

                        cache.adjust_max_size(new_size)
                        logger.info(
                            "cache_size_adjusted",
                            cache_name=cache_name,
                            old_size=current_size,
                            new_size=new_size,
                        )
                except Exception:
                    continue

        except Exception as e:
            logger.error("cache_size_adjustment_failed", error=str(e))

    async def _adjust_task_queue_priorities(self):
        """ì‘ì—… í ìš°ì„ ìˆœìœ„ ì¡°ì •"""
        try:
            # ë†’ì€ ìš°ì„ ìˆœìœ„: ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬
            # ë‚®ì€ ìš°ì„ ìˆœìœ„: ë°°ì¹˜ ì‘ì—…, ë¦¬í¬íŠ¸ ìƒì„±

            priority_adjustments = {
                "price_monitoring": 10,  # ë†’ì€ ìš°ì„ ìˆœìœ„
                "technical_analysis": 8,  # ë†’ì€ ìš°ì„ ìˆœìœ„
                "news_crawling": 6,  # ì¤‘ê°„ ìš°ì„ ìˆœìœ„
                "report_generation": 3,  # ë‚®ì€ ìš°ì„ ìˆœìœ„
                "batch_analysis": 2,  # ë‚®ì€ ìš°ì„ ìˆœìœ„
                "data_cleanup": 1,  # ê°€ì¥ ë‚®ì€ ìš°ì„ ìˆœìœ„
            }

            # ì‘ì—… í ì‹œìŠ¤í…œì— ìš°ì„ ìˆœìœ„ ì ìš© (ì‹¤ì œ êµ¬í˜„ì— ë”°ë¼ ì¡°ì • í•„ìš”)
            logger.info(
                "task_queue_priorities_adjusted", priorities=priority_adjustments
            )

        except Exception as e:
            logger.error("task_queue_priority_adjustment_failed", error=str(e))

    async def _adjust_cache_ttl(self, increase: bool = True):
        """ìºì‹œ TTL ì¡°ì •"""
        try:
            cache_names = ["technical_analysis", "price_data", "news_data"]

            for cache_name in cache_names:
                try:
                    cache = get_cache(cache_name)
                    if hasattr(cache, "adjust_default_ttl"):
                        current_ttl = getattr(cache, "default_ttl", 300)  # ê¸°ë³¸ 5ë¶„
                        if increase:
                            new_ttl = min(
                                3600, int(current_ttl * 1.5)
                            )  # 50% ì¦ê°€, ìµœëŒ€ 1ì‹œê°„
                        else:
                            new_ttl = max(
                                60, int(current_ttl * 0.7)
                            )  # 30% ê°ì†Œ, ìµœì†Œ 1ë¶„

                        cache.adjust_default_ttl(new_ttl)
                        logger.info(
                            "cache_ttl_adjusted",
                            cache_name=cache_name,
                            old_ttl=current_ttl,
                            new_ttl=new_ttl,
                        )
                except Exception:
                    continue

        except Exception as e:
            logger.error("cache_ttl_adjustment_failed", error=str(e))

    async def _perform_cache_warmup(self):
        """ìºì‹œ ì›Œë°ì—… ì‹¤í–‰"""
        try:
            # ìì£¼ ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ìºì‹œì— ë¡œë“œ
            warmup_tasks = [
                self._warmup_technical_analysis_cache(),
                self._warmup_price_data_cache(),
                self._warmup_news_cache(),
            ]

            await asyncio.gather(*warmup_tasks, return_exceptions=True)
            logger.info("cache_warmup_completed")

        except Exception as e:
            logger.error("cache_warmup_failed", error=str(e))

    async def _warmup_technical_analysis_cache(self):
        """ê¸°ìˆ ì  ë¶„ì„ ìºì‹œ ì›Œë°ì—…"""
        try:
            # ì£¼ìš” ì‹¬ë³¼ë“¤ì˜ ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ë¥¼ ë¯¸ë¦¬ ê³„ì‚°í•˜ì—¬ ìºì‹œì— ì €ì¥
            major_symbols = ["AAPL", "GOOGL", "MSFT", "TSLA", "AMZN"]

            for symbol in major_symbols:
                try:
                    # ì‹¤ì œ ê¸°ìˆ ì  ë¶„ì„ ì„œë¹„ìŠ¤ í˜¸ì¶œ (êµ¬í˜„ì— ë”°ë¼ ì¡°ì •)
                    # await technical_analysis_service.get_analysis(symbol)
                    await asyncio.sleep(0.1)  # ì‹œë®¬ë ˆì´ì…˜
                except Exception:
                    continue

        except Exception as e:
            logger.error("technical_analysis_cache_warmup_failed", error=str(e))

    async def _warmup_price_data_cache(self):
        """ê°€ê²© ë°ì´í„° ìºì‹œ ì›Œë°ì—…"""
        try:
            # ì£¼ìš” ì‹¬ë³¼ë“¤ì˜ ê°€ê²© ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ìºì‹œì— ë¡œë“œ
            major_symbols = ["AAPL", "GOOGL", "MSFT", "TSLA", "AMZN"]

            for symbol in major_symbols:
                try:
                    # ì‹¤ì œ ê°€ê²© ë°ì´í„° ì„œë¹„ìŠ¤ í˜¸ì¶œ (êµ¬í˜„ì— ë”°ë¼ ì¡°ì •)
                    # await price_service.get_current_price(symbol)
                    await asyncio.sleep(0.1)  # ì‹œë®¬ë ˆì´ì…˜
                except Exception:
                    continue

        except Exception as e:
            logger.error("price_data_cache_warmup_failed", error=str(e))

    async def _warmup_news_cache(self):
        """ë‰´ìŠ¤ ìºì‹œ ì›Œë°ì—…"""
        try:
            # ìµœì‹  ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ìºì‹œì— ë¡œë“œ
            # await news_service.get_latest_news()
            await asyncio.sleep(0.1)  # ì‹œë®¬ë ˆì´ì…˜

        except Exception as e:
            logger.error("news_cache_warmup_failed", error=str(e))

    async def _emergency_cache_cleanup(self):
        """ì‘ê¸‰ ìºì‹œ ì •ë¦¬"""
        try:
            cache_names = ["technical_analysis", "price_data", "news_data"]

            for cache_name in cache_names:
                try:
                    cache = get_cache(cache_name)
                    # ì˜¤ë˜ëœ ìºì‹œ í•­ëª© ì •ë¦¬
                    if hasattr(cache, "cleanup_expired"):
                        cache.cleanup_expired()
                    # ìºì‹œ í¬ê¸°ê°€ ë„ˆë¬´ í° ê²½ìš° ì¼ë¶€ ì •ë¦¬
                    if hasattr(cache, "cleanup_lru"):
                        cache.cleanup_lru(keep_ratio=0.5)  # 50%ë§Œ ìœ ì§€

                    logger.info(
                        "emergency_cache_cleanup_completed", cache_name=cache_name
                    )
                except Exception:
                    continue

        except Exception as e:
            logger.error("emergency_cache_cleanup_failed", error=str(e))

    async def _emergency_memory_cleanup(self):
        """ì‘ê¸‰ ë©”ëª¨ë¦¬ ì •ë¦¬"""
        try:
            import gc

            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
            collected = gc.collect()

            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
            memory_info = psutil.virtual_memory()

            logger.info(
                "emergency_memory_cleanup_completed",
                collected_objects=collected,
                memory_usage_percent=memory_info.percent,
            )

        except Exception as e:
            logger.error("emergency_memory_cleanup_failed", error=str(e))

    def _print_performance_status(self, metrics: PerformanceMetrics):
        """ì„±ëŠ¥ ìƒíƒœ ì¶œë ¥"""
        # ìƒíƒœì— ë”°ë¥¸ ì´ëª¨ì§€
        status_emoji = {
            PerformanceStatus.EXCELLENT: "ğŸŸ¢",
            PerformanceStatus.GOOD: "ğŸ”µ",
            PerformanceStatus.FAIR: "ğŸŸ¡",
            PerformanceStatus.POOR: "ğŸŸ ",
            PerformanceStatus.CRITICAL: "ğŸ”´",
        }

        emoji = status_emoji.get(metrics.status, "âšª")

        print(
            f"\n{emoji} [{metrics.timestamp.strftime('%H:%M:%S')}] "
            f"ìƒíƒœ: {metrics.status.value.upper()}"
        )
        print(
            f"   ğŸ’¾ ë©”ëª¨ë¦¬: {metrics.memory_usage_percent:.1f}% | "
            f"ğŸ–¥ï¸ CPU: {metrics.cpu_usage_percent:.1f}%"
        )
        print(
            f"   â±ï¸ ì‘ë‹µì‹œê°„: {metrics.avg_response_time_ms:.1f}ms | "
            f"ğŸ“Š P95: {metrics.p95_response_time_ms:.1f}ms"
        )
        print(
            f"   ğŸ¯ ìºì‹œ íˆíŠ¸ìœ¨: {metrics.cache_hit_rate_percent:.1f}% | "
            f"âŒ ì—ëŸ¬ìœ¨: {metrics.error_rate_percent:.1f}%"
        )
        print(
            f"   ğŸ”— í™œì„± ì—°ê²°: {metrics.active_connections} | "
            f"ğŸ“ˆ RPS: {metrics.requests_per_second:.1f}"
        )

    def get_performance_summary(self, hours: int = 24) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        try:
            cutoff_time = datetime.now() - timedelta(hours=hours)
            recent_metrics = [
                m for m in self.performance_history if m.timestamp > cutoff_time
            ]

            if not recent_metrics:
                return {"error": "No metrics available"}

            # í†µê³„ ê³„ì‚°
            memory_usage = [m.memory_usage_percent for m in recent_metrics]
            cpu_usage = [m.cpu_usage_percent for m in recent_metrics]
            response_times = [m.avg_response_time_ms for m in recent_metrics]
            cache_hit_rates = [m.cache_hit_rate_percent for m in recent_metrics]

            # ìƒíƒœë³„ ë¶„í¬
            status_counts = {}
            for status in PerformanceStatus:
                status_counts[status.value] = sum(
                    1 for m in recent_metrics if m.status == status
                )

            return {
                "period_hours": hours,
                "total_measurements": len(recent_metrics),
                "memory_usage": {
                    "avg": statistics.mean(memory_usage),
                    "max": max(memory_usage),
                    "min": min(memory_usage),
                },
                "cpu_usage": {
                    "avg": statistics.mean(cpu_usage),
                    "max": max(cpu_usage),
                    "min": min(cpu_usage),
                },
                "response_time": {
                    "avg": statistics.mean(response_times),
                    "max": max(response_times),
                    "min": min(response_times),
                    "p95": self._percentile(response_times, 95),
                },
                "cache_hit_rate": {
                    "avg": statistics.mean(cache_hit_rates),
                    "max": max(cache_hit_rates),
                    "min": min(cache_hit_rates),
                },
                "status_distribution": status_counts,
                "last_updated": recent_metrics[-1].timestamp.isoformat(),
            }

        except Exception as e:
            logger.error("performance_summary_failed", error=str(e))
            return {"error": str(e)}

    def _percentile(self, data: List[float], percentile: int) -> float:
        """ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚°"""
        sorted_data = sorted(data)
        index = int((percentile / 100) * len(sorted_data))
        return sorted_data[min(index, len(sorted_data) - 1)]

    def save_performance_history(self, filepath: str):
        """ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ì €ì¥"""
        try:
            history_data = [asdict(metrics) for metrics in self.performance_history]

            # datetime ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            for item in history_data:
                item["timestamp"] = item["timestamp"].isoformat()
                item["status"] = item["status"].value

            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(history_data, f, indent=2, ensure_ascii=False)

            logger.info(
                "performance_history_saved", filepath=filepath, count=len(history_data)
            )

        except Exception as e:
            logger.error("performance_history_save_failed", error=str(e))


class PerformanceTuningRecommendations:
    """ì„±ëŠ¥ íŠœë‹ ê¶Œì¥ì‚¬í•­ ìƒì„±ê¸°"""

    def __init__(self):
        self.logger = get_logger(__name__)

    def generate_recommendations(
        self, metrics_history: List[PerformanceMetrics]
    ) -> List[Dict[str, Any]]:
        """ì„±ëŠ¥ íŠœë‹ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []

        if not metrics_history:
            return recommendations

        try:
            # ìµœê·¼ ë©”íŠ¸ë¦­ ë¶„ì„
            recent_metrics = (
                metrics_history[-10:] if len(metrics_history) >= 10 else metrics_history
            )

            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„
            memory_recommendations = self._analyze_memory_usage(recent_metrics)
            recommendations.extend(memory_recommendations)

            # ì‘ë‹µ ì‹œê°„ ë¶„ì„
            response_time_recommendations = self._analyze_response_times(recent_metrics)
            recommendations.extend(response_time_recommendations)

            # ìºì‹œ ì„±ëŠ¥ ë¶„ì„
            cache_recommendations = self._analyze_cache_performance(recent_metrics)
            recommendations.extend(cache_recommendations)

            # ì „ë°˜ì ì¸ ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„
            trend_recommendations = self._analyze_performance_trends(metrics_history)
            recommendations.extend(trend_recommendations)

            return recommendations

        except Exception as e:
            self.logger.error("recommendation_generation_failed", error=str(e))
            return []

    def _analyze_memory_usage(
        self, metrics: List[PerformanceMetrics]
    ) -> List[Dict[str, Any]]:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„"""
        recommendations = []

        avg_memory = statistics.mean([m.memory_usage_percent for m in metrics])
        max_memory = max([m.memory_usage_percent for m in metrics])

        if avg_memory > 80:
            recommendations.append(
                {
                    "category": "memory",
                    "priority": "high",
                    "title": "ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ",
                    "description": f"í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ {avg_memory:.1f}%ë¡œ ë†’ìŠµë‹ˆë‹¤.",
                    "recommendations": [
                        "ë©”ëª¨ë¦¬ ìµœì í™” ë°ì½”ë ˆì´í„° ì ìš© í™•ëŒ€",
                        "ìºì‹œ í¬ê¸° ì¡°ì •",
                        "ë¶ˆí•„ìš”í•œ ë°ì´í„° ì •ë¦¬ ìŠ¤ì¼€ì¤„ ì¶”ê°€",
                    ],
                }
            )

        if max_memory > 95:
            recommendations.append(
                {
                    "category": "memory",
                    "priority": "critical",
                    "title": "ë©”ëª¨ë¦¬ ë¶€ì¡± ìœ„í—˜",
                    "description": f"ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ {max_memory:.1f}%ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.",
                    "recommendations": [
                        "ì¦‰ì‹œ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤í–‰",
                        "ë©”ëª¨ë¦¬ ì§‘ì•½ì  ì‘ì—… ë¶„ì‚°",
                        "ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ í™•ì¥ ê²€í† ",
                    ],
                }
            )

        return recommendations

    def _analyze_response_times(
        self, metrics: List[PerformanceMetrics]
    ) -> List[Dict[str, Any]]:
        """ì‘ë‹µ ì‹œê°„ ë¶„ì„"""
        recommendations = []

        avg_response = statistics.mean([m.avg_response_time_ms for m in metrics])
        p95_response = statistics.mean([m.p95_response_time_ms for m in metrics])

        if avg_response > 1000:
            recommendations.append(
                {
                    "category": "response_time",
                    "priority": "high",
                    "title": "ëŠë¦° ì‘ë‹µ ì‹œê°„",
                    "description": f"í‰ê·  ì‘ë‹µ ì‹œê°„ì´ {avg_response:.1f}msë¡œ ëŠë¦½ë‹ˆë‹¤.",
                    "recommendations": [
                        "ë¹„ë™ê¸° ì²˜ë¦¬ í™•ëŒ€",
                        "ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ìµœì í™”",
                        "ìºì‹± ì „ëµ ê°œì„ ",
                    ],
                }
            )

        if p95_response > 3000:
            recommendations.append(
                {
                    "category": "response_time",
                    "priority": "medium",
                    "title": "P95 ì‘ë‹µ ì‹œê°„ ê°œì„  í•„ìš”",
                    "description": f"P95 ì‘ë‹µ ì‹œê°„ì´ {p95_response:.1f}msì…ë‹ˆë‹¤.",
                    "recommendations": [
                        "ë¬´ê±°ìš´ ì‘ì—…ì„ ë°±ê·¸ë¼ìš´ë“œë¡œ ì´ì „",
                        "ì‘ì—… í ìš°ì„ ìˆœìœ„ ì¡°ì •",
                        "íƒ€ì„ì•„ì›ƒ ì„¤ì • ê²€í† ",
                    ],
                }
            )

        return recommendations

    def _analyze_cache_performance(
        self, metrics: List[PerformanceMetrics]
    ) -> List[Dict[str, Any]]:
        """ìºì‹œ ì„±ëŠ¥ ë¶„ì„"""
        recommendations = []

        avg_hit_rate = statistics.mean([m.cache_hit_rate_percent for m in metrics])

        if avg_hit_rate < 70:
            recommendations.append(
                {
                    "category": "cache",
                    "priority": "medium",
                    "title": "ë‚®ì€ ìºì‹œ íˆíŠ¸ìœ¨",
                    "description": f"í‰ê·  ìºì‹œ íˆíŠ¸ìœ¨ì´ {avg_hit_rate:.1f}%ë¡œ ë‚®ìŠµë‹ˆë‹¤.",
                    "recommendations": [
                        "ìºì‹œ TTL ì¡°ì •",
                        "ìºì‹œ í‚¤ ì „ëµ ê°œì„ ",
                        "ìºì‹œ ì›Œë°ì—… ìŠ¤ì¼€ì¤„ ì¶”ê°€",
                    ],
                }
            )

        return recommendations

    def _analyze_performance_trends(
        self, metrics: List[PerformanceMetrics]
    ) -> List[Dict[str, Any]]:
        """ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„"""
        recommendations = []

        if len(metrics) < 20:
            return recommendations

        try:
            # ìµœê·¼ 10ê°œì™€ ì´ì „ 10ê°œ ë¹„êµ
            recent = metrics[-10:]
            previous = metrics[-20:-10]

            recent_avg_response = statistics.mean(
                [m.avg_response_time_ms for m in recent]
            )
            previous_avg_response = statistics.mean(
                [m.avg_response_time_ms for m in previous]
            )

            if recent_avg_response > previous_avg_response * 1.2:  # 20% ì´ìƒ ì¦ê°€
                recommendations.append(
                    {
                        "category": "trend",
                        "priority": "medium",
                        "title": "ì„±ëŠ¥ ì €í•˜ íŠ¸ë Œë“œ",
                        "description": "ìµœê·¼ ì‘ë‹µ ì‹œê°„ì´ ì§€ì†ì ìœ¼ë¡œ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                        "recommendations": [
                            "ì„±ëŠ¥ ì €í•˜ ì›ì¸ ë¶„ì„",
                            "ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ê°•í™”",
                            "ì˜ˆë°©ì  ìµœì í™” ì ìš©",
                        ],
                    }
                )

        except Exception as e:
            self.logger.error("trend_analysis_failed", error=str(e))

        return recommendations


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ë°°í¬ í›„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì‹œì‘")
    print("=" * 50)

    # ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    monitor = PostDeploymentMonitor(monitoring_interval=60)  # 1ë¶„ ê°„ê²©

    try:
        # ëª¨ë‹ˆí„°ë§ ì‹œì‘
        await monitor.start_monitoring()

    except KeyboardInterrupt:
        print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ëª¨ë‹ˆí„°ë§ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        monitor.stop_monitoring()

        # ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        history_file = f"performance_history_{timestamp}.json"
        monitor.save_performance_history(history_file)

        # ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥
        summary = monitor.get_performance_summary(hours=1)
        print("\nğŸ“Š ì„±ëŠ¥ ìš”ì•½ (ìµœê·¼ 1ì‹œê°„):")
        print(json.dumps(summary, indent=2, ensure_ascii=False))

        # íŠœë‹ ê¶Œì¥ì‚¬í•­ ìƒì„±
        recommender = PerformanceTuningRecommendations()
        recommendations = recommender.generate_recommendations(
            monitor.performance_history
        )

        if recommendations:
            print("\nğŸ’¡ ì„±ëŠ¥ íŠœë‹ ê¶Œì¥ì‚¬í•­:")
            for i, rec in enumerate(recommendations, 1):
                print(f"\n{i}. {rec['title']} ({rec['priority']} ìš°ì„ ìˆœìœ„)")
                print(f"   ì„¤ëª…: {rec['description']}")
                print("   ê¶Œì¥ì‚¬í•­:")
                for suggestion in rec["recommendations"]:
                    print(f"   - {suggestion}")

    except Exception as e:
        print(f"âŒ ëª¨ë‹ˆí„°ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        logger.error("monitoring_system_error", error=str(e))


if __name__ == "__main__":
    # ë¹„ë™ê¸° ì‹¤í–‰
    asyncio.run(main())
