#!/usr/bin/env python3
"""
ê°„ë‹¨í•œ K-means í´ëŸ¬ìŠ¤í„°ë§ í…ŒìŠ¤íŠ¸

íŒ¨í„´ ë°ì´í„°ì˜ ì‹¤ì œ ìƒí™©ì— ë§ì¶° í´ëŸ¬ìŠ¤í„°ë§ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import os
import sys
from datetime import datetime
from typing import List, Dict, Any
import json

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.common.infra.database.config.database_config import SessionLocal
from app.technical_analysis.infra.model.entity.signal_patterns import SignalPattern
from app.technical_analysis.infra.model.entity.pattern_clusters import PatternCluster
from app.technical_analysis.infra.model.repository.pattern_cluster_repository import (
    PatternClusterRepository,
)


def extract_simple_features(pattern: SignalPattern) -> List[float]:
    """íŒ¨í„´ì—ì„œ ê°„ë‹¨í•œ íŠ¹ì„± ì¶”ì¶œ"""
    features = []

    # íŒ¨í„´ ì´ë¦„ ê¸°ë°˜ íŠ¹ì„±
    name = pattern.pattern_name.lower() if pattern.pattern_name else ""

    # 1. ì‹ í˜¸ íƒ€ì…ë³„ ì›-í•« ì¸ì½”ë”©
    signal_types = ["ma50", "ma200", "rsi", "bb", "macd", "volume"]
    for signal_type in signal_types:
        features.append(1.0 if signal_type in name else 0.0)

    # 2. ë°©í–¥ì„± (ìƒìŠ¹/í•˜ë½)
    bullish_terms = ["up", "breakout_up", "golden", "oversold"]
    bearish_terms = ["down", "breakout_down", "dead", "overbought"]

    bullish_score = sum(1 for term in bullish_terms if term in name)
    bearish_score = sum(1 for term in bearish_terms if term in name)

    features.append(min(bullish_score / 2.0, 1.0))  # ì •ê·œí™”
    features.append(min(bearish_score / 2.0, 1.0))  # ì •ê·œí™”

    # 3. íŒ¨í„´ ë³µì¡ë„ (ì´ë¦„ ê¸¸ì´ ê¸°ë°˜)
    complexity = min(len(name.split("_")) / 10.0, 1.0)
    features.append(complexity)

    # 4. ì‹œê°„ì  íŠ¹ì„±
    if pattern.pattern_start:
        features.append(pattern.pattern_start.weekday() / 6.0)  # ìš”ì¼
        features.append(pattern.pattern_start.month / 12.0)  # ì›”
    else:
        features.extend([0.5, 0.5])

    return features


def simple_kmeans(
    feature_vectors: List[List[float]], n_clusters: int = 6
) -> List[List[int]]:
    """ê°„ë‹¨í•œ K-means í´ëŸ¬ìŠ¤í„°ë§"""
    if not feature_vectors or n_clusters <= 0:
        return []

    n_features = len(feature_vectors[0])
    n_points = len(feature_vectors)

    if n_points < n_clusters:
        n_clusters = max(2, n_points // 2)

    # ì´ˆê¸° ì¤‘ì‹¬ì  ì„¤ì • (ë” ë‚˜ì€ ì´ˆê¸°í™”)
    import random

    random.seed(42)

    centroids = []
    for i in range(n_clusters):
        # ë°ì´í„° ë²”ìœ„ ë‚´ì—ì„œ ëœë¤ ì¤‘ì‹¬ì  ìƒì„±
        centroid = []
        for j in range(n_features):
            feature_values = [vec[j] for vec in feature_vectors]
            min_val, max_val = min(feature_values), max(feature_values)
            centroid.append(random.uniform(min_val, max_val))
        centroids.append(centroid)

    # K-means ë°˜ë³µ
    for iteration in range(100):
        # ê° ì ì„ ê°€ì¥ ê°€ê¹Œìš´ ì¤‘ì‹¬ì ì— í• ë‹¹
        clusters = [[] for _ in range(n_clusters)]

        for i, point in enumerate(feature_vectors):
            distances = []
            for centroid in centroids:
                # ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°
                distance = sum((p - c) ** 2 for p, c in zip(point, centroid)) ** 0.5
                distances.append(distance)

            closest_cluster = distances.index(min(distances))
            clusters[closest_cluster].append(i)

        # ìƒˆë¡œìš´ ì¤‘ì‹¬ì  ê³„ì‚°
        new_centroids = []
        for cluster_indices in clusters:
            if cluster_indices:
                # í´ëŸ¬ìŠ¤í„° ë‚´ ì ë“¤ì˜ í‰ê· 
                cluster_points = [feature_vectors[i] for i in cluster_indices]
                centroid = []
                for j in range(n_features):
                    avg = sum(point[j] for point in cluster_points) / len(
                        cluster_points
                    )
                    centroid.append(avg)
                new_centroids.append(centroid)
            else:
                # ë¹ˆ í´ëŸ¬ìŠ¤í„°ëŠ” ê¸°ì¡´ ì¤‘ì‹¬ì  ìœ ì§€
                new_centroids.append(centroids[len(new_centroids)])

        # ìˆ˜ë ´ ì²´í¬
        converged = True
        for old, new in zip(centroids, new_centroids):
            distance = sum((o - n) ** 2 for o, n in zip(old, new)) ** 0.5
            if distance > 0.001:
                converged = False
                break

        centroids = new_centroids

        if converged:
            print(f"âœ… K-means ìˆ˜ë ´ ì™„ë£Œ (ë°˜ë³µ: {iteration + 1}íšŒ)")
            break

    return clusters


def analyze_cluster(
    cluster_patterns: List[SignalPattern], cluster_features: List[List[float]]
) -> Dict[str, Any]:
    """í´ëŸ¬ìŠ¤í„° íŠ¹ì„± ë¶„ì„"""
    if not cluster_patterns:
        return {}

    # íŒ¨í„´ ì´ë¦„ ë¶„ì„
    pattern_names = [p.pattern_name for p in cluster_patterns if p.pattern_name]

    # ê³µí†µ ìš©ì–´ ì°¾ê¸°
    all_terms = []
    for name in pattern_names:
        all_terms.extend(name.lower().split("_"))

    term_counts = {}
    for term in all_terms:
        term_counts[term] = term_counts.get(term, 0) + 1

    # ê°€ì¥ ë¹ˆë²ˆí•œ ìš©ì–´ë“¤
    common_terms = sorted(term_counts.items(), key=lambda x: x[1], reverse=True)[:3]

    # ë°©í–¥ì„± ë¶„ì„
    bullish_count = sum(
        1
        for name in pattern_names
        if any(term in name.lower() for term in ["up", "breakout_up"])
    )
    bearish_count = sum(
        1
        for name in pattern_names
        if any(term in name.lower() for term in ["down", "breakout_down"])
    )

    bullish_tendency = bullish_count / len(pattern_names) if pattern_names else 0
    bearish_tendency = bearish_count / len(pattern_names) if pattern_names else 0

    # ì„±ê³µë¥  ì¶”ì • (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
    if bullish_tendency > 0.6:
        success_rate = 65.0  # ìƒìŠ¹ íŒ¨í„´ì€ ë†’ì€ ì„±ê³µë¥ 
    elif bearish_tendency > 0.6:
        success_rate = 60.0  # í•˜ë½ íŒ¨í„´ë„ ë†’ì€ ì„±ê³µë¥ 
    else:
        success_rate = 50.0  # ì¤‘ë¦½ íŒ¨í„´

    return {
        "pattern_count": len(cluster_patterns),
        "common_terms": [term for term, count in common_terms],
        "bullish_tendency": bullish_tendency,
        "bearish_tendency": bearish_tendency,
        "avg_success_rate": success_rate,
        "dominant_signal_types": list(
            set(term for term, count in common_terms if count > 1)
        ),
    }


def generate_cluster_name(cluster_stats: Dict[str, Any], cluster_id: int) -> str:
    """í´ëŸ¬ìŠ¤í„° ì´ë¦„ ìƒì„±"""
    common_terms = cluster_stats.get("common_terms", [])
    bullish_tendency = cluster_stats.get("bullish_tendency", 0)
    bearish_tendency = cluster_stats.get("bearish_tendency", 0)

    # ì£¼ìš” ìš©ì–´ ê¸°ë°˜ ì´ë¦„ ìƒì„±
    if common_terms:
        main_term = common_terms[0]
        if bullish_tendency > 0.6:
            return f"{main_term.upper()}_ìƒìŠ¹_íŒ¨í„´"
        elif bearish_tendency > 0.6:
            return f"{main_term.upper()}_í•˜ë½_íŒ¨í„´"
        else:
            return f"{main_term.upper()}_ì¤‘ë¦½_íŒ¨í„´"
    else:
        return f"í´ëŸ¬ìŠ¤í„°_{cluster_id}"


def save_cluster_results(
    symbol: str,
    clusters: List[List[int]],
    patterns: List[SignalPattern],
    feature_vectors: List[List[float]],
) -> int:
    """í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ë¥¼ DBì— ì €ì¥"""
    session = SessionLocal()
    cluster_repo = PatternClusterRepository(session)

    saved_count = 0
    clustered_at = datetime.utcnow()

    try:
        for cluster_id, cluster_indices in enumerate(clusters):
            if not cluster_indices:
                continue

            # í´ëŸ¬ìŠ¤í„° íŒ¨í„´ë“¤
            cluster_patterns = [patterns[i] for i in cluster_indices]
            cluster_features = [feature_vectors[i] for i in cluster_indices]

            # í´ëŸ¬ìŠ¤í„° ë¶„ì„
            cluster_stats = analyze_cluster(cluster_patterns, cluster_features)
            cluster_name = generate_cluster_name(cluster_stats, cluster_id)

            # í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì  ê³„ì‚°
            if cluster_features:
                n_features = len(cluster_features[0])
                cluster_center = []
                for j in range(n_features):
                    avg = sum(features[j] for features in cluster_features) / len(
                        cluster_features
                    )
                    cluster_center.append(avg)
            else:
                cluster_center = []

            # ëŒ€í‘œ íŒ¨í„´ ì„ íƒ (ìµœëŒ€ 5ê°œ)
            representative_patterns = [p.id for p in cluster_patterns[:5]]

            # PatternCluster ì—”í‹°í‹° ìƒì„±
            pattern_cluster = PatternCluster(
                symbol=symbol,
                cluster_id=cluster_id,
                cluster_name=cluster_name,
                timeframe="1day",
                pattern_count=len(cluster_patterns),
                avg_success_rate=cluster_stats.get("avg_success_rate", 50.0),
                avg_confidence_score=75.0,  # ê¸°ë³¸ê°’
                avg_duration_hours=0.0,  # í˜„ì¬ ë°ì´í„°ì—ì„œëŠ” 0
                bullish_tendency=cluster_stats.get("bullish_tendency", 0.0),
                bearish_tendency=cluster_stats.get("bearish_tendency", 0.0),
                dominant_signal_types=json.dumps(
                    cluster_stats.get("dominant_signal_types", [])
                ),
                cluster_center=json.dumps(cluster_center),
                cluster_radius=0.5,  # ê¸°ë³¸ê°’
                representative_patterns=json.dumps(representative_patterns),
                pattern_examples=json.dumps(
                    {
                        "main_patterns": [p.pattern_name for p in cluster_patterns[:3]],
                        "cluster_description": f"{cluster_name} - {len(cluster_patterns)}ê°œ íŒ¨í„´",
                    }
                ),
                clustering_algorithm="kmeans",
                n_clusters_total=len(clusters),
                clustering_quality_score=80.0,  # ê¸°ë³¸ê°’
                clustered_at=clustered_at,
            )

            # DBì— ì €ì¥
            cluster_repo.save(pattern_cluster)
            saved_count += 1

            print(
                f"  âœ… {cluster_name}: {len(cluster_patterns)}ê°œ íŒ¨í„´ (ì„±ê³µë¥ : {cluster_stats.get('avg_success_rate', 50.0):.1f}%)"
            )

        session.commit()
        return saved_count

    except Exception as e:
        session.rollback()
        print(f"âŒ í´ëŸ¬ìŠ¤í„° ì €ì¥ ì‹¤íŒ¨: {e}")
        return 0
    finally:
        session.close()


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 80)
    print("ğŸ§  ê°„ë‹¨í•œ K-means í´ëŸ¬ìŠ¤í„°ë§ í…ŒìŠ¤íŠ¸")
    print("=" * 80)

    symbols = ["^IXIC", "^GSPC"]

    for symbol in symbols:
        print(f"\nğŸ”„ {symbol} í´ëŸ¬ìŠ¤í„°ë§ ì‹œì‘...")

        # ì„¸ì…˜ ìƒì„±
        session = SessionLocal()

        try:
            # íŒ¨í„´ ë°ì´í„° ì¡°íšŒ
            patterns = (
                session.query(SignalPattern)
                .filter(SignalPattern.symbol == symbol)
                .all()
            )

            if len(patterns) < 10:
                print(f"âš ï¸ {symbol}: íŒ¨í„´ì´ ë¶€ì¡±í•©ë‹ˆë‹¤ ({len(patterns)}ê°œ)")
                continue

            print(f"ğŸ“Š {symbol}: {len(patterns)}ê°œ íŒ¨í„´ ë°œê²¬")

            # íŠ¹ì„± ë²¡í„° ì¶”ì¶œ
            feature_vectors = []
            valid_patterns = []

            for pattern in patterns:
                features = extract_simple_features(pattern)
                if features and len(features) == 11:  # ì˜ˆìƒ íŠ¹ì„± ê°œìˆ˜
                    feature_vectors.append(features)
                    valid_patterns.append(pattern)

            print(f"âœ… {symbol}: {len(feature_vectors)}ê°œ íŒ¨í„´ì˜ íŠ¹ì„± ë²¡í„° ìƒì„±")

            if len(feature_vectors) < 6:
                print(f"âš ï¸ {symbol}: í´ëŸ¬ìŠ¤í„°ë§ì„ ìœ„í•œ íŒ¨í„´ì´ ë¶€ì¡±í•©ë‹ˆë‹¤")
                continue

            # K-means í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰
            print(f"ğŸ§  {symbol} K-means í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰...")
            clusters = simple_kmeans(feature_vectors, n_clusters=6)

            # ê²°ê³¼ ì¶œë ¥
            non_empty_clusters = [c for c in clusters if c]
            print(f"âœ… {symbol}: {len(non_empty_clusters)}ê°œ í´ëŸ¬ìŠ¤í„° ìƒì„±")

            for i, cluster_indices in enumerate(clusters):
                if cluster_indices:
                    print(f"  - í´ëŸ¬ìŠ¤í„° {i}: {len(cluster_indices)}ê°œ íŒ¨í„´")

            # DBì— ì €ì¥
            print(f"ğŸ’¾ {symbol} í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ì €ì¥...")
            saved_count = save_cluster_results(
                symbol, clusters, valid_patterns, feature_vectors
            )
            print(f"âœ… {symbol}: {saved_count}ê°œ í´ëŸ¬ìŠ¤í„° ì €ì¥ ì™„ë£Œ")

        except Exception as e:
            print(f"âŒ {symbol} í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨: {e}")
        finally:
            session.close()

    print("\n" + "=" * 80)
    print("ğŸ‰ í´ëŸ¬ìŠ¤í„°ë§ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 80)


if __name__ == "__main__":
    main()
